<!doctype html public "-//w3c//dtd html 4.0 transitional//en">
<html>
<head>
   <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
   <meta name="description" content="varianceTool">
   <meta name="keywords" content="varianceTool">
   <meta name="resource-type" content="document">
   <meta name="distribution" content="global">
   <meta name="Generator" content="LaTeX2HTML v2K.1beta">
   <meta http-equiv="Content-Style-Type" content="text/css">
   <meta name="GENERATOR" content="Mozilla/4.78 [en] (X11; U; Linux 2.4.7-10smp i686) [Netscape]">
   <title>varianceTool</title>
<!--Converted with LaTeX2HTML 2K.1beta (1.47)
original version by:  Nikos Drakos, CBLU, University of Leeds
* revised and updated by:  Marcus Hennecke, Ross Moore, Herb Swan
* with significant contributions from:
  Jens Lippmann, Marek Rouchal, Martin Wilck and others -->
<link REL="STYLESHEET" HREF="varianceTool.css">
</head>
<body>
&nbsp;
<center><b>HYPOTHESIS TESTING FOR THE MEAN</b></center>

<center><b>OF A ONE VARIABLE DATA SET</b></center>

<center><b>(1) GENERAL THEORY OF HYPOTHESIS TESTING</b></center>

<p>In that <b>estimation theory</b> we considered sampling from a population
and then estimating parameter values from the computed sample information.
We now discuss <b>statistical testing</b> or <b>hypothesis testing</b>.
Much of the theoretical framework is the same as in estimation theory but
the viewpoint is different. In hypothesis testing we begin with a claim
or <b>hypothesis</b> about a population parameter and then test this claim
by looking at sample information.
<p>Suppose that standard guidelines say that the average time to complete
a certain surgical procedure is 2 hours or 120 minutes. We take the claim
of an average of 120 minutes as a <b>hypothesis</b> about the true population
mean and we wish to test whether this is correct or not. Suppose further
that a random sample of 25 of these surgical procedures had an average
(sample average) completion time of 151 minutes. Then the observed evidence
is that it actually takes longer than 120 minutes on average. Of course
the difference between the theoretical avergae of 120 minutes and the observed
value of 151 minutes may be soley due to random variation. If we use the
computed sample mean of 151 minutes as evidence that either the claim that
the population mean is 120 is correct or that the claim is too low this
is an example of a <b>hypothesis testing procedure</b>. Essentially here
we are looking at whether the observed value, 151 minutes, is far enough
away from the hypothesized mean of 120 minutes to be evidence that 120
is too low. The criteria used to determine in a scientific manner whether
it is far enough away will be discussed below.
<p>What is crucial in statistical hypothesis testing is that the general
procedure is not to prove the hypothesis but rather <b>to attempt to disprove
the hypothesis</b>. For this reason the hypotheses that we test in statistics
are called <b>null hypotheses</b> because we are trying to null them or
negate them. If we cannot null them or negate them we accept them. Null
hypotheses are denoted by&nbsp;<img SRC="img74.gif" ALT="$ H_0$" BORDER=0 height=29 width=25 align=CENTER>
and generally have the form<!-- MATH
 \begin{displaymath}
H_0: \theta = \theta_0
\end{displaymath}
 -->
<center><img SRC="img75.gif" ALT="$\displaystyle H_0: \theta = \theta_0$" BORDER=0 height=29 width=81 align=CENTER></center>
where&nbsp;<img SRC="img12.gif" ALT="$ \theta$" BORDER=0 height=15 width=12 align=BOTTOM>
is a parameter and&nbsp;<img SRC="img76.gif" ALT="$ \theta_0$" BORDER=0 height=29 width=19 align=CENTER>
is a particular value.
<p>In the example involving the surgical procedure time the parameter being
tested is the population mean&nbsp;<img SRC="img2.gif" ALT="$ \mu$" BORDER=0 height=28 width=14 align=CENTER>
and the claim is that this mean is 120 minutes. Therefore for this test
the null hypothesis is<!-- MATH
 \begin{displaymath}
H_0: \mu = 120.
\end{displaymath}
 -->
<center><img SRC="img77.gif" ALT="$\displaystyle H_0: \mu = 120.$" BORDER=0 height=29 width=97 align=CENTER></center>
EXAMPLE 6 Suppose we consider two different hospitals A and B and we wish
to determine if the average per patient cost for a given procedure is the
same in both hospitals. If we let&nbsp;<img SRC="img78.gif" ALT="$ \mu_A$" BORDER=0 height=28 width=24 align=CENTER>
be the average per patient cost in hospital A and&nbsp;<img SRC="img79.gif" ALT="$ \mu_B$" BORDER=0 height=28 width=25 align=CENTER>
be the average per patient cost in hospital B then the parameter being
testing is&nbsp;<!-- MATH
 $\mu_A - \mu_B$
 --><img SRC="img80.gif" ALT="$ \mu_A - \mu_B$" BORDER=0 height=28 width=64 align=CENTER>
the difference of the two means. The appropriate null hypothesis is then<!-- MATH
 \begin{displaymath}
H_0:\mu_A - \mu_B = 0
\end{displaymath}
 -->
<center><img SRC="img81.gif" ALT="$\displaystyle H_0:\mu_A - \mu_B = 0$" BORDER=0 height=29 width=127 align=CENTER></center>
a difference of 0 indicating no difference between the two hospitals.
<br>&nbsp;
<br>&nbsp;
<p>To actually test a given null hypothesis we roughly proceed as follows:
for an estimator statistic&nbsp;<img SRC="img14.gif" ALT="$ \th$" BORDER=0 height=14 width=4 align=BOTTOM>
for&nbsp;<img SRC="img12.gif" ALT="$ \theta$" BORDER=0 height=15 width=12 align=BOTTOM>
we have a cutoff value&nbsp;<img SRC="img82.gif" ALT="$ c$" BORDER=0 height=14 width=11 align=BOTTOM>.
If&nbsp;<img SRC="img83.gif" ALT="$ \th >c$" BORDER=0 height=28 width=28 align=CENTER>
we reject the null hypothesis while otherwise we accept it. Which estimator
statistic to use, how the value of&nbsp;<img SRC="img82.gif" ALT="$ c$" BORDER=0 height=14 width=11 align=BOTTOM>
is determined and how to actually carry out the analysis we will now discuss.
<p>In testing a null hypothesis&nbsp;<!-- MATH
 $H_0: \theta = \theta_0$
 --><img SRC="img84.gif" ALT="$ H_0: \theta = \theta_0$" BORDER=0 height=29 width=81 align=CENTER>
the idea is to attempt to disprove it or reject it. We must therefore have
an <b>alternative hypothesis</b>, which we denote by&nbsp;<img SRC="img85.gif" ALT="$ H_1$" BORDER=0 height=29 width=25 align=CENTER>
to accept if we do reject&nbsp;<img SRC="img74.gif" ALT="$ H_0$" BORDER=0 height=29 width=25 align=CENTER>.
The alternative hypothesis can have one of three possible forms:<!-- MATH
 \begin{displaymath}
H_1: \theta \ne \theta_0
\end{displaymath}
 -->
<center><img SRC="img86.gif" ALT="$\displaystyle H_1: \theta \ne \theta_0$" BORDER=0 height=29 width=81 align=CENTER></center>
<!-- MATH
 \begin{displaymath}
H_1: \theta > \theta_0
\end{displaymath}
 -->
<center><img SRC="img87.gif" ALT="$\displaystyle H_1: \theta > \theta_0$" BORDER=0 height=29 width=81 align=CENTER></center>
<!-- MATH
 \begin{displaymath}
H_1: \theta < \theta_0.
\end{displaymath}
 -->
<center><img SRC="img88.gif" ALT="$\displaystyle H_1: \theta < \theta_0.$" BORDER=0 height=29 width=86 align=CENTER></center>
The first form is called a <b>two-sided alternative</b> while the second
two forms are called <b>one-sided alternatives</b>. Usually the alternative
hypothesis is what is really believed to be true in the test. The null
hypothesis is set up in such a manner so that if it is rejected we arrive
at the appropriate alternative.
<p>EXAMPLE
<p>In the test of surgical time we had the null hypothesis<!-- MATH
 \begin{displaymath}
H_0:\mu = 120.
\end{displaymath}
 -->
<center><img SRC="img77.gif" ALT="$\displaystyle H_0: \mu = 120.$" BORDER=0 height=29 width=97 align=CENTER></center>
The computed evidence is that this figure is too low or equivalently that
the true mean is higher. Therefore in this case the appropriate alternative
is<!-- MATH
 \begin{displaymath}
H_1: \mu > 120.
\end{displaymath}
 -->
<center><img SRC="img89.gif" ALT="$\displaystyle H_1: \mu > 120.$" BORDER=0 height=29 width=97 align=CENTER></center>
This is a one-sided alternative.
<br>&nbsp;
<br>&nbsp;
<p>Once a null hypothesis and alternative hypothesis are chosen we have
the following schematic situation (figure 1) which contains all the relevant
information about statistical testing.
<center><img SRC="Anal_Var_5.gif" BORDER=0 height=195 width=336 align=CENTER></center>

<center>Figure 1 Hypothesis Testing</center>

<p>A <b>type 1 error</b> is the error of rejecting a null hypothesis when
it is really true. Here we randomly get a sample which refutes the null
hypothesis even though the null hypothesis is true. The probability or
risk of committing a type 1 error is called the <b>level of significance</b>
or<!-- MATH
 $\bold{\alpha}$
 --><img SRC="img90.gif" ALT="$ \bold{\alpha}$" BORDER=0 height=14 width=14 align=BOTTOM>-<b>error</b>
(alpha error). A <b>type 2 error</b> is the error of accepting a null hypothesis
when it is really false. Here we randomly obtain a sample which backs up
the null hypothesis even though the null hypothesis is false. The probability
or risk of committing a type 1 error is called the&nbsp;<!-- MATH
 $\bold{\beta}$
 --><img SRC="img91.gif" ALT="$ \bold{\beta}$" BORDER=0 height=29 width=14 align=CENTER>-<b>error</b>
(beta error). It is also called the
<b>operating characteristic value</b>.
The probability of not committing a type 2 error {the lower right hand
box} is&nbsp;<img SRC="img92.gif" ALT="$ 1- \beta$" BORDER=0 height=29 width=41 align=CENTER>
and is called the <b>power of the test</b>. If there are two possible tests
for a hypothesis the more powerful test is the one with the higher power.
The values of<img SRC="img35.gif" ALT="$ \alpha$" BORDER=0 height=14 width=14 align=BOTTOM>
and&nbsp;<img SRC="img93.gif" ALT="$ \beta$" BORDER=0 height=29 width=14 align=CENTER>
are inversely related for a fixed sample size. That is if there is a small<img SRC="img35.gif" ALT="$ \alpha$" BORDER=0 height=14 width=14 align=BOTTOM>,
that is a small chance of making a type 1 error, there may be a larger&nbsp;<img SRC="img93.gif" ALT="$ \beta$" BORDER=0 height=29 width=14 align=CENTER>,
or a larger chance of making a type 2 error. If we wish to maintain a small&nbsp;<img SRC="img35.gif" ALT="$ \alpha$" BORDER=0 height=14 width=14 align=BOTTOM>
and have a smaller<img SRC="img93.gif" ALT="$ \beta$" BORDER=0 height=29 width=14 align=CENTER>
we must take a larger sample size. The relationship between&nbsp;<img SRC="img35.gif" ALT="$ \alpha$" BORDER=0 height=14 width=14 align=BOTTOM>
and&nbsp;<img SRC="img93.gif" ALT="$ \beta$" BORDER=0 height=29 width=14 align=CENTER>
is analogous to the relationship between confidence and accuracy in an
estimation procedure.
<p>In setting up a criterion for accepting or rejecting a null hypothesis&nbsp;<img SRC="img74.gif" ALT="$ H_0$" BORDER=0 height=29 width=25 align=CENTER>
we attempt to set the level of significance at a predetermined small value.
In most practical testing this value is either 1% or 5% although any value
can be used. For example if a test is conducted at a 5% level of significance
this means that there is only a 5% chance of rejecting the null hypothesis
if it is really true.
<p>There is a nice analogy between the hypothesis testing framework and
the framework of the criminal justice system in the United States. When
a defendant goes into court the presumption is innocent until proven guilty.
The burden of proof is all on the prosecution. Hence the defendants innocence
is a null hypothesis while the alternative is the defendant's guilt. Therefore
we have<!-- MATH
 \begin{displaymath}
H_O: \text{ Defendant is Inncoent}
\end{displaymath}
 -->
<center><img SRC="img94.gif" ALT="$\displaystyle H_O:$" BORDER=0 height=29 width=37 align=CENTER>&nbsp;&nbsp;&nbsp;
Defendant is Inncoent</center>
<!-- MATH
 \begin{displaymath}
H_1: \text{ Defendant is Guilty}.
\end{displaymath}
 -->
<center><img SRC="img95.gif" ALT="$\displaystyle H_1:$" BORDER=0 height=29 width=33 align=CENTER>&nbsp;&nbsp;&nbsp;
Defendant is Guilty<img SRC="img96.gif" ALT="$\displaystyle .$" BORDER=0 height=28 width=8 align=CENTER></center>
Then there is the following schematic.
<center><img SRC="Anal_Var_2.gif" BORDER=0 height=195 width=336 align=CENTER></center>

<center>Figure 2 Legal Analogy</center>

<p>Hence in this legal analogy the&nbsp;<img SRC="img35.gif" ALT="$ \alpha$" BORDER=0 height=14 width=14 align=BOTTOM>-error
is convicting an inncoent defendant while the<img SRC="img93.gif" ALT="$ \beta$" BORDER=0 height=29 width=14 align=CENTER>-error
is letting a guilty defendant go free. Historically the American legal
system has been geared to making&nbsp;<img SRC="img35.gif" ALT="$ \alpha$" BORDER=0 height=14 width=14 align=BOTTOM>
as small as possible. What must be realized is that this follows the above
theoretical model so that&nbsp;<img SRC="img35.gif" ALT="$ \alpha$" BORDER=0 height=14 width=14 align=BOTTOM>
and&nbsp;<img SRC="img93.gif" ALT="$ \beta$" BORDER=0 height=29 width=14 align=CENTER>
are inversely related. In practical terms this means that anything that
is done to make it harder to convict an innocent person will increase the
probability of letting a guilty person go free. Conversely anything done
to make it harder for a guilty person to go free will increase the probability
of convicting an innocent person.
<center><b>(2) GENERAL STATISTICAL TESTING PROCEDURE</b></center>
For any statistical hypothesis test there is a five step procedure that
is always followed. What will differ in this procedure in going from test
to test is the type of test statistic used and the determination of critical
regions. We will go over this procedure, do some examples and then in the
rest of the chapter go over the particular types of tests most relevant
to nursing and medical practice.
<br>&nbsp;
<br>&nbsp;
<p>The <b>first step</b> in the testing procedure is to <b>formulate the
null hypothesis<img SRC="img74.gif" ALT="$ H_0$" BORDER=0 height=29 width=25 align=CENTER></b>.
As explained in section 6.1 this will usually have the form&nbsp;<!-- MATH
 $\theta = \theta_0$
 --><img SRC="img97.gif" ALT="$ \theta = \theta_0$" BORDER=0 height=29 width=48 align=CENTER>
where&nbsp;<img SRC="img12.gif" ALT="$ \theta$" BORDER=0 height=15 width=12 align=BOTTOM>
is a parameter and&nbsp;<img SRC="img76.gif" ALT="$ \theta_0$" BORDER=0 height=29 width=19 align=CENTER>
is a particular value. Recall that we are not trying to prove this null
hypothesis but rather to disprove it or reject it. If we cannot reject
it it will be accepted.
<br>&nbsp;
<br>&nbsp;
<p>The <b>second step</b> in the testing procedure is to <b>formulate the
alternative hypothesis<img SRC="img85.gif" ALT="$ H_1$" BORDER=0 height=29 width=25 align=CENTER></b>
which will be accepted if the null hypothesis is rejected. As explained
in the last section the alternative hypothesis can have one of three possible
forms:<!-- MATH
 \begin{displaymath}
H_1: \theta \ne \theta_0
\end{displaymath}
 -->
<center><img SRC="img86.gif" ALT="$\displaystyle H_1: \theta \ne \theta_0$" BORDER=0 height=29 width=81 align=CENTER></center>
<!-- MATH
 \begin{displaymath}
H_1: \theta > \theta_0
\end{displaymath}
 -->
<center><img SRC="img87.gif" ALT="$\displaystyle H_1: \theta > \theta_0$" BORDER=0 height=29 width=81 align=CENTER></center>
<!-- MATH
 \begin{displaymath}
H_1: \theta < \theta_0.
\end{displaymath}
 -->
<center><img SRC="img88.gif" ALT="$\displaystyle H_1: \theta < \theta_0.$" BORDER=0 height=29 width=86 align=CENTER></center>
The first form is called a <b>two-sided alternative</b> while the second
two forms are called <b>one-sided alternatives</b>. The alternative hypothesis
i usually what is really believed in the test. The null hypothesis is set
up in such a manner so that if it is rejected we arrive at the appropriate
alternative.
<br>&nbsp;
<br>&nbsp;
<p>The <b>third step</b> in the testing procedure is to choose three things:
a <b>level of significance</b>, a <b>sample size</b> and an <b>appropriate
test statistic</b>.
<p>The level of significance is the probability of making a type 1 error,
that is the probability of rejecting the null hypothesis when it is true.
It is chosen to be a small number, usually 1% or 5%, although any value
can be used. If we reject at 1% value then we are 99% confident that we
made the right decision.
<p>The appropriate test statistic is a statistic whose sampling distribution
depends upon the parameter being tested. We wish to find the cutoff value
so that the probability of the observed value of the test statistic is
low (less than the level of significance) if the null hypothesis is false.
How we arrive at appropriate test statistics will be discussed in subsequent
sections.
<br>&nbsp;
<br>&nbsp;
<p>The <b>fourth step</b> in the testing procedure is to determine a <b>rejection
region</b> or <b>critical region</b>. This region will serve as the cutoff
for accepting or rejecting the null hypothesis. If the observed value of
the test statistic falls in the rejection region the null hypothesis will
be rejectedd. If the observed value of the test statistic doesn't fall
in the rejection region then the null hypothesis will be accepted. The
determination of the critical region will be based on the level of significance
and the sampling distribution of the test statistic and will be determined
so that the probability of a value of the test statistic falling the critical
region is less than the level of significance. Again we will see how this
is done for specific test statistics in subsequent sections.
<br>&nbsp;
<br>&nbsp;
<p>The <b>fifth step</b> and final step in the testing procedure is to
obtain sample results and a value for the test statistic. If the test results
are in the rejection region the results are said to be <b>statistically
significant</b> and the null hypothesis&nbsp;<img SRC="img74.gif" ALT="$ H_0$" BORDER=0 height=29 width=25 align=CENTER>
is rejected in favor of the alternative&nbsp;<img SRC="img85.gif" ALT="$ H_1$" BORDER=0 height=29 width=25 align=CENTER>.
If the test results are not in the rejection region then we say the results
are
<b>not statistically significant</b> and the null hypothesis&nbsp;<img SRC="img74.gif" ALT="$ H_0$" BORDER=0 height=29 width=25 align=CENTER>
is accepted. Thus significant results lead to rejection of the null hypothesis
while not significant results lead to acceptance of the null hypothesis.
<p>Another concept is important relative to this fifth step. The <b>P-value</b>
of the test results is the probability of obtaining a value of the test
statistic more unusual that what was obtained, assuming the null hypothesis
is true. If there is a level of significance&nbsp;<img SRC="img35.gif" ALT="$ \alpha$" BORDER=0 height=14 width=14 align=BOTTOM>,
then being in the rejection region is equivalent to having a P-value less
than&nbsp;<img SRC="img35.gif" ALT="$ \alpha$" BORDER=0 height=14 width=14 align=BOTTOM>.
Hence the null hypothesis is rejected whenever the P-value is less than
the given level of significance. Therefore we have the following two equivalent
rejection criteria:
<p><!-- MATH
 $\hphantom{xx}$
 --><img SRC="img98.gif" ALT="$ \hphantom{xx}$" BORDER=0 height=14 width=22 align=BOTTOM>
(1) The value of the test statistic falls in the rejection region
<p><!-- MATH
 $\hphantom{xx}$
 --><img SRC="img98.gif" ALT="$ \hphantom{xx}$" BORDER=0 height=14 width=22 align=BOTTOM>
(2) The P-value of the test results are lower than the level of significance<img SRC="img35.gif" ALT="$ \alpha$" BORDER=0 height=14 width=14 align=BOTTOM>.
<p>The second criteria is important to note since many computer programs
print the P-values. In using these programs the rejection regions don't
have to be determined - just the computed P-values compared with the given&nbsp;<img SRC="img35.gif" ALT="$ \alpha$" BORDER=0 height=14 width=14 align=BOTTOM>.
.
<p>We now summarize the five step procedure and then do several examples.
<br>&nbsp;
<br>&nbsp;
<center><b>FIVE STEP HYPOTHESIS TESTING PROCEDURE</b></center>

<p><br><!-- MATH
 $\hphantom{xx}$
 --><img SRC="img98.gif" ALT="$ \hphantom{xx}$" BORDER=0 height=14 width=22 align=BOTTOM>
<b>STEP ONE</b>: Formulate the null hypothesis:&nbsp;<!-- MATH
 \begin{displaymath}
H_0: \theta = \theta_0
\end{displaymath}
 -->
<center><img SRC="img75.gif" ALT="$\displaystyle H_0: \theta = \theta_0$" BORDER=0 height=29 width=81 align=CENTER></center>
where&nbsp;<img SRC="img12.gif" ALT="$ \theta$" BORDER=0 height=15 width=12 align=BOTTOM>
is a parameter and&nbsp;<img SRC="img76.gif" ALT="$ \theta_0$" BORDER=0 height=29 width=19 align=CENTER>
a particular value.
<br>&nbsp;
<p><!-- MATH
 $\hphantom{xx}$
 --><img SRC="img98.gif" ALT="$ \hphantom{xx}$" BORDER=0 height=14 width=22 align=BOTTOM>
<b>STEP TWO</b>: Formulate the alternative hypothesis:<!-- MATH
 \begin{displaymath}
H_1: \theta \ne \theta_0 \text { or}
\end{displaymath}
 -->
<center><img SRC="img86.gif" ALT="$\displaystyle H_1: \theta \ne \theta_0$" BORDER=0 height=29 width=81 align=CENTER><img SRC="img99.gif" ALT="$\displaystyle \text { or}$" BORDER=0 height=28 width=19 align=CENTER></center>
<!-- MATH
 \begin{displaymath}
H_1: \theta > \theta_0 \text { or}
\end{displaymath}
 -->
<center><img SRC="img87.gif" ALT="$\displaystyle H_1: \theta > \theta_0$" BORDER=0 height=29 width=81 align=CENTER><img SRC="img99.gif" ALT="$\displaystyle \text { or}$" BORDER=0 height=28 width=19 align=CENTER></center>
<!-- MATH
 \begin{displaymath}
H_1: \theta < \theta_0.
\end{displaymath}
 -->
<center><img SRC="img88.gif" ALT="$\displaystyle H_1: \theta < \theta_0.$" BORDER=0 height=29 width=86 align=CENTER></center>

<p><!-- MATH
 $\hphantom{xx}$
 --><img SRC="img98.gif" ALT="$ \hphantom{xx}$" BORDER=0 height=14 width=22 align=BOTTOM>
<b>STEP THREE</b>: Choose a <b>level of significance<img SRC="img35.gif" ALT="$ \alpha$" BORDER=0 height=14 width=14 align=BOTTOM></b>,
a <b>sample size<img SRC="img9.gif" ALT="$ n$" BORDER=0 height=14 width=14 align=BOTTOM></b>
and <b>an appropriate test statistic</b>.
<br>&nbsp;
<br>&nbsp;
<p><!-- MATH
 $\hphantom{xx}$
 --><img SRC="img98.gif" ALT="$ \hphantom{xx}$" BORDER=0 height=14 width=22 align=BOTTOM>
<b>STEP FOUR</b>: Based on the sampling distribution of the test statistic
and the chosen level of significance determine a <b>rejection region</b>
or <b>critical region</b>. The values not in the rejection region are called
the <b>acceptance region</b>.
<br>&nbsp;
<br>&nbsp;
<p><!-- MATH
 $\hphantom{xx}$
 --><img SRC="img98.gif" ALT="$ \hphantom{xx}$" BORDER=0 height=14 width=22 align=BOTTOM>
<b>STEP FIVE</b>: Obtain test results and a value for the test statistic.
<p><!-- MATH
 $\hphantom{xxxxx}$
 --><img SRC="img100.gif" ALT="$ \hphantom{xxxxx}$" BORDER=0 height=14 width=50 align=BOTTOM>
(a) If the test results are in the rejection region the results are said
to be <b>statistically significant</b> and the null hypothesis&nbsp;<img SRC="img74.gif" ALT="$ H_0$" BORDER=0 height=29 width=25 align=CENTER>
is rejected in favor of the alternative&nbsp;<img SRC="img85.gif" ALT="$ H_1$" BORDER=0 height=29 width=25 align=CENTER>.
This is equivalent to the P-value of the test results being lower than
the level of significance.
<p><!-- MATH
 $\hphantom{xxxxx}$
 --><img SRC="img100.gif" ALT="$ \hphantom{xxxxx}$" BORDER=0 height=14 width=50 align=BOTTOM>
(b)If the test results are not in the rejection region then we say the
results are
<b>not statistically significant</b> and the null hypothesis&nbsp;<img SRC="img74.gif" ALT="$ H_0$" BORDER=0 height=29 width=25 align=CENTER>
is accepted. This is equivalent to the P-value of the results being higher
than the level of significance.
<br>&nbsp;
<br>&nbsp;
<p>EXAMPLE It is claimed that the average production time for a certain
produced item is 26 minutes. There is some evidence that it actually takes
longer. To test the claim, 64 items were sampled. A sample average production
time of&nbsp;<img SRC="img101.gif" ALT="$ \X = 27.5$" BORDER=0 height=14 width=49 align=BOTTOM>
minutes with a standard deviation of&nbsp;<img SRC="img102.gif" ALT="$ s = 4.5$" BORDER=0 height=14 width=53 align=BOTTOM>
minutes was computed. Is this enough evidence at a 5% level of significance
to reject the claim.
<p>Here the null hypothesis is&nbsp;<img SRC="img103.gif" ALT="$ \mu = 26$" BORDER=0 height=28 width=51 align=CENTER>
matching the claim. We are interested in the fact that it actually takes
longer so the alternative is&nbsp;<img SRC="img104.gif" ALT="$ \mu > 26$" BORDER=0 height=28 width=51 align=CENTER>.
This is a one-sided alternative. Hence we have<!-- MATH
 \begin{displaymath}
H_0: \mu = 26
\end{displaymath}
 -->
<center><img SRC="img105.gif" ALT="$\displaystyle H_0: \mu = 26$" BORDER=0 height=29 width=85 align=CENTER></center>
<!-- MATH
 \begin{displaymath}
H_1: \mu > 26
\end{displaymath}
 -->
<center><img SRC="img106.gif" ALT="$\displaystyle H_1: \mu > 26$" BORDER=0 height=29 width=85 align=CENTER></center>
This takes care of steps one and two.
<p>The sample size is&nbsp;<img SRC="img107.gif" ALT="$ n = 64$" BORDER=0 height=14 width=51 align=BOTTOM>
while the chosen level of significance is&nbsp;<!-- MATH
 $\alpha = .05$
 --><img SRC="img108.gif" ALT="$ \alpha = .05$" BORDER=0 height=14 width=56 align=BOTTOM>.
An appropriate test statistic for testing hypotheses concenring means (see
section 6.5) is&nbsp;<!-- MATH
 \begin{displaymath}
z = \frac{\X - \mu}{\frac{s}{\sqrt{n}}}.
\end{displaymath}
 -->
<center><img SRC="img109.gif" ALT="$\displaystyle z = \frac{\X - \mu}{\frac{s}{\sqrt{n}}}.$" BORDER=0 height=47 width=64 align=CENTER></center>
Recall from the last chapter that for large sample sizes the above statistic
has an approximate normal distribution. This means that in step four we
will use the normal distribution to determine the rejection region.
<p>In figure 3 we see a normal distribution with a supposed mean of&nbsp;<img SRC="img103.gif" ALT="$ \mu = 26$" BORDER=0 height=28 width=51 align=CENTER>.
This corresponds to a z-value of&nbsp;<img SRC="img110.gif" ALT="$ z = 0$" BORDER=0 height=14 width=41 align=BOTTOM>.
Given the alternative&nbsp;<img SRC="img104.gif" ALT="$ \mu > 26$" BORDER=0 height=28 width=51 align=CENTER>
it is clear that high values of the mean will lead to rejection. The 5%
level tells us how high - only the highest 5% will lead to rejection. From
the standard normal table we find (as in chapter four) that a z-value of&nbsp;<img SRC="img111.gif" ALT="$ z = 1.65$" BORDER=0 height=14 width=62 align=BOTTOM>
cuts off the highest 5%. This is called the <b>critical z-value</b>, which
we denote by&nbsp;<img SRC="img112.gif" ALT="$ z_c$" BORDER=0 height=28 width=18 align=CENTER>.
Here then i&nbsp;<!-- MATH
 $z_c = 1.65$
 --><img SRC="img113.gif" ALT="$ z_c = 1.65$" BORDER=0 height=28 width=67 align=CENTER>.
This is the cutoff above which there will be rejection. Notice that since
the alternative is one-sided only one tail of the normal curve leads to
rejection. Tests like this are then called <b>one-tailed tests</b>. If
both tails led to rejection it would be called a <b>two-tailed test</b>.
<center><img SRC="Anal_Var_3.gif" BORDER=0 height=195 width=336 align=CENTER></center>

<center>figure 3 Rejection Region</center>
The sample results are:<!-- MATH
 \begin{displaymath}
\X = 27.5, s = 4.5 \text{ and } n = 64
\end{displaymath}
 -->
<center><img SRC="img114.gif" ALT="$\displaystyle \X = 27.5, s = 4.5$" BORDER=0 height=28 width=105 align=CENTER>&nbsp;&nbsp;&nbsp;
and&nbsp;<img SRC="img115.gif" ALT="$\displaystyle n = 64$" BORDER=0 height=28 width=51 align=CENTER></center>
therefore the value of the test statistic is<!-- MATH
 \begin{displaymath}
z = \frac{27.5 - 26}{\frac{4.5}{8}} = 2.67.
\end{displaymath}
 -->
<center><img SRC="img116.gif" ALT="$\displaystyle z = \frac{27.5 - 26}{\frac{4.5}{8}} = 2.67.$" BORDER=0 height=49 width=155 align=CENTER></center>
This value falls in the rejection region and therefore the results are
significant. It follows that the null hypothesis of&nbsp;<img SRC="img103.gif" ALT="$ \mu = 26$" BORDER=0 height=28 width=51 align=CENTER>
is rejected in favor of the alternative&nbsp;<img SRC="img104.gif" ALT="$ \mu > 26$" BORDER=0 height=28 width=51 align=CENTER>.
<p>The results would be reported in the following manner.
<br>&nbsp;
<p>At a 5% level the result were significant. Therefore the null hypothesis
that the mean was 26 is rejected in favor of the alternative that the mean
is greater than 26.
<br>&nbsp;
<br>&nbsp;
<p>From A normal table we see that there is a probability of only .0037
of obtaining a z-value of over 2.67. Hence the P-value of the above test
results is .0037. This is below&nbsp;<!-- MATH
 $\alpha = .05$
 --><img SRC="img108.gif" ALT="$ \alpha = .05$" BORDER=0 height=14 width=56 align=BOTTOM>.
Again using the P-value criterion the null hypothesis would be rejected
since the P-value is lower than the chosen level.
<br>&nbsp;
<br>&nbsp;
<p>It should be clear from this example that the testing procedure is rather
straightforward once an appropriate test statistic and its sampling distribution
is known. Therefore what must be done now is to describe the important
testing situations together with the appropriate corresponding test statistics.
<br>&nbsp;
<br>&nbsp;
<center><b>(3) OVERVIEW OF PARAMETRIC TESTING</b></center>

<p>In most practical testing situations there are three population parameters
that may be of interest:
<b>means</b>, <b>standard deviations</b> and <b>proportions</b>.
Hypotheses on these parameters can be tested in several different ways.
<p>In a <b>one-sample test</b>, the value of the parameter is tested against
some predetermined standard or target value. The sample results in a single
sample are used to either accept of reject that standard. Both examples
in the previous section were one sample tests.
<p>In a <b>two-sample test</b>, independent samples from two different
populations are used to determine comparisons between the parameters of
the two populations. For example in comparing whether the completion time
of two surgical procedures differs between hospital A and hospital B independent
samples would be drawn from each and then compared.
<p>In <b>multiple sample tests</b> parameters from many different populations
are tested in one test.
<p>Therefore there are nine basic situations which the statistical analyst
must be acquainted with: one sample, two sample and multiple sample for
means; one sample, two sample and multiple sample for standard deviations;
and one sample, two sample and multiple sample for proportions. Within
each of these nine basic situations testing may differ depending on whether
large or small samples are drawn. The analyst must be acquainted with this
also. The chart in figure 4 gives an overview picture of this parametric
testing.
<center><img SRC="Anal_Var_4.gif" BORDER=0 height=195 width=336 align=CENTER></center>

<center>figure 4 Parametric Testing Overview</center>

<p>Tests of means are generally called <b>t-tests</b> because they use
the t-distribution Multiple sample tests of means fall into what are called
<b>analysis of variance</b> or <b>ANOVA</b> procedures. One sample tests
of standard deviations use the chi-square distribution while two sample
and multiple sample tests for standard deviations use the F-distribution
and are called <b>F-tests</b>. One and two sample tests of proportions
are called
<b>p-tests </b>and are usually based on the normal distribution.
Multiple sample tests use the chi-square distribution and will be discussed
in the next chapter. Multiple sample procedures can also be used for two
sample testing.
<br>&nbsp;
<br>&nbsp;
<center><b>(3) HYPTHESIS TESTS FOR A SINGLE VARIANCE</b></center>

<center><b>OR STANDARD DEVIATION</b></center>

<p>The variation of a population or a data set is crucial to understanding
research results. Therefore it is often quite important to test questions
about variances and standard deviations. In doing such tests we generally
assume that the parent population is normal. Test results concerning variances
are equivalent to tests concerning standard deviations.
<p>For a one variable data set, representing a single population, null
hypotheses are of the form<!-- MATH
 \begin{displaymath}
H_0: \sigma^2 = \sigma_0^2 \tag 1
\end{displaymath}
 -->
<center><img SRC="img117.gif" ALT="$\displaystyle H_0: \sigma^2 = \sigma_0^2 \tag 1$" BORDER=0 height=35 width=100 align=CENTER></center>
or<!-- MATH
 \begin{displaymath}
H_0: \sigma = \sigma_0.
\end{displaymath}
 -->
<center><img SRC="img118.gif" ALT="$\displaystyle H_0: \sigma = \sigma_0.$" BORDER=0 height=29 width=89 align=CENTER></center>
In these,&nbsp;<img SRC="img3.gif" ALT="$ \sigma$" BORDER=0 height=14 width=14 align=BOTTOM>
is the population standard deviation and&nbsp;<img SRC="img119.gif" ALT="$ \sigma_0$" BORDER=0 height=28 width=20 align=CENTER>
is a particular value.
<p>An appropriate test statistic for dealing with (1) is<!-- MATH
 \begin{displaymath}
\chi^2 = \frac{(n-1)s^2}{\sigma_0^2} \tag 2
\end{displaymath}
 -->
<center><img SRC="img120.gif" ALT="$\displaystyle \chi^2 = \frac{(n-1)s^2}{\sigma_0^2} \tag 2$" BORDER=0 height=55 width=118 align=CENTER></center>
which has a chi-square distribution with&nbsp;<img SRC="img46.gif" ALT="$ n-1$" BORDER=0 height=28 width=41 align=CENTER>
degrees of freedom. Therefore the critical values and rejection region
will be found from the chi-square distribution.
<p>EXAMPLE
<p>A filling machine is supposed to have a variance of .01 liters. A random
sample of 16 fills showed a sample variance of .014 liters. Is this significant
at a 5% level that the variance is too large.
<p>The null and alternative hypotheses are<!-- MATH
 \begin{displaymath}
H_0: \sigma^2 = .01
\end{displaymath}
 -->
<center><img SRC="img121.gif" ALT="$\displaystyle H_0: \sigma^2 = .01$" BORDER=0 height=35 width=96 align=CENTER></center>
<!-- MATH
 \begin{displaymath}
H_1: \sigma^2 > .01.
\end{displaymath}
 -->
<center><img SRC="img122.gif" ALT="$\displaystyle H_1: \sigma^2 > .01.$" BORDER=0 height=35 width=100 align=CENTER></center>
The test statistic is given by 6.7.2 which follows a chi-square distribution
with 15 degrees of freedom. The critical chi-square value would be found
from the chi-square table<!-- MATH
 \begin{displaymath}
\chi^2_c = \chi^2_{.05,15} = 24.996.
\end{displaymath}
 -->
<center><img SRC="img123.gif" ALT="$\displaystyle \chi^2_c = \chi^2_{.05,15} = 24.996.$" BORDER=0 height=35 width=156 align=CENTER></center>
The sample results were that&nbsp;<img SRC="img59.gif" ALT="$ n = 16$" BORDER=0 height=14 width=51 align=BOTTOM>
and&nbsp;<!-- MATH
 $s^2 = .014$
 --><img SRC="img124.gif" ALT="$ s^2 = .014$" BORDER=0 height=17 width=68 align=BOTTOM>
hence the test statistic value is<!-- MATH
 \begin{displaymath}
\chi^2 = \frac{(15)(.014)}{.01} = 21.
\end{displaymath}
 -->
<center><img SRC="img125.gif" ALT="$\displaystyle \chi^2 = \frac{(15)(.014)}{.01} = 21.$" BORDER=0 height=53 width=157 align=CENTER></center>
This is not significant so therefore at a 5% level there is no evidence
that the variance is too high.
<br>&nbsp;
<br>&nbsp;
<p>There is a large sample technique that can be employed also with tests
of variances for a one variable data set. If the sample size is large (<img SRC="img126.gif" ALT="$ n > 30 $" BORDER=0 height=28 width=51 align=CENTER>)
then<!-- MATH
 \begin{displaymath}
z = \frac{s-\sigma_0}{\frac{\sigma_0}{\sqrt{2n}}} \3
\end{displaymath}
 -->
<center><img SRC="img127.gif" ALT="$\displaystyle z = \frac{s-\sigma_0}{\frac{\sigma_0}{\sqrt{2n}}} \3$" BORDER=0 height=47 width=80 align=CENTER></center>
has an approximate normal distribution. Notice in this test statistic we
use the standard deviation rather than the variance.
<br>&nbsp;
<br>&nbsp;
<p>EXAMPLE
<p>Suppose that in the filling machine of the first example, which is supposed
to have a variance of .01 liters, a random sample of 100 fills showed a
sample variance of .014 liters. Is this significant at a 5% level that
the variance is too large.
<p>The null and alternative hypotheses are<!-- MATH
 \begin{displaymath}
H_0: \sigma^2 = .01
\end{displaymath}
 -->
<center><img SRC="img121.gif" ALT="$\displaystyle H_0: \sigma^2 = .01$" BORDER=0 height=35 width=96 align=CENTER></center>
<!-- MATH
 \begin{displaymath}
H_1: \sigma^2 > .01.
\end{displaymath}
 -->
<center><img SRC="img122.gif" ALT="$\displaystyle H_1: \sigma^2 > .01.$" BORDER=0 height=35 width=100 align=CENTER></center>
Since now&nbsp;<img SRC="img128.gif" ALT="$ n = 100$" BORDER=0 height=14 width=59 align=BOTTOM>
a large sample procedure can be used and the test statistic is given by
6.7.3 which follows a normal distribution. The critical z-value for 5%
and a one-sided test is&nbsp;<!-- MATH
 $z_c = 1.65$
 --><img SRC="img113.gif" ALT="$ z_c = 1.65$" BORDER=0 height=28 width=67 align=CENTER>.
Here&nbsp;<!-- MATH
 $\sigma_0^2 = .01$
 --><img SRC="img129.gif" ALT="$ \sigma_0^2 = .01$" BORDER=0 height=33 width=62 align=CENTER>
so&nbsp;<!-- MATH
 $\sigma_0 = \sqrt{.01} =
.1$
 --><img SRC="img130.gif" ALT="$ \sigma_0 = \sqrt{.01} =.1$" BORDER=0 height=36 width=109 align=CENTER>.
The sample results were&nbsp;<!-- MATH
 \begin{displaymath}
n = 100, s^2 = .014 \implies s = \sqrt{.014} = .118.
\end{displaymath}
 -->
<center><img SRC="img131.gif" ALT="$\displaystyle n = 100, s^2 = .014 \implies s = \sqrt{.014} = .118.$" BORDER=0 height=38 width=254 align=CENTER></center>
The test statistic value is<!-- MATH
 \begin{displaymath}
z = \frac{.118-.1}{\frac{.118}{\sqrt{200}}} = 2.16.
\end{displaymath}
 -->
<center><img SRC="img132.gif" ALT="$\displaystyle z = \frac{.118-.1}{\frac{.118}{\sqrt{200}}} = 2.16.$" BORDER=0 height=49 width=151 align=CENTER></center>
This is significant so therefore at a 5% level there is evidence that the
variance is too high.
<br>&nbsp;
<br>&nbsp;
<p>The significance in this second case points out that tests are more
powerful for larger sample sizes.
<p>Note that in conducting these tests using MAGNUSSTAT the P-values will
be computed automatically and the appropriate decision ( accept or reject)
based on the user defined level of significance will be presented in the
output box.
<p>;''
<br>
<hr>
</body>
</html>
