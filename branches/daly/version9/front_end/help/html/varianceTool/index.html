<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">

<!--Converted with LaTeX2HTML 2K.1beta (1.47)
original version by:  Nikos Drakos, CBLU, University of Leeds
* revised and updated by:  Marcus Hennecke, Ross Moore, Herb Swan
* with significant contributions from:
  Jens Lippmann, Marek Rouchal, Martin Wilck and others -->
<HTML>
<HEAD>
<TITLE>varianceTool</TITLE>
<META NAME="description" CONTENT="varianceTool">
<META NAME="keywords" CONTENT="varianceTool">
<META NAME="resource-type" CONTENT="document">
<META NAME="distribution" CONTENT="global">

<META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=iso-8859-1">
<META NAME="Generator" CONTENT="LaTeX2HTML v2K.1beta">
<META HTTP-EQUIV="Content-Style-Type" CONTENT="text/css">

<LINK REL="STYLESHEET" HREF="varianceTool.css">

</HEAD>

<BODY >

<P>
<!-- MATH
 $\vphantom{xxx}$
 -->
<IMG
 WIDTH="4" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img1.gif"
 ALT="$ \vphantom{xxx}$">

<P>
<DIV ALIGN="CENTER">
<B>THE ANALYSIS OF THE VARIANCE TOOL</B></DIV>

<P>

<P><P>
<BR>

<P>
The <B>Analysis of the Variance Tool</B> will perform two standard inference procedures for the
population variance or standard deviation of the population from which the given one variable data
set has been drawn.  

<P>
The first procedure is to construct a <B>confidence interval </B> for the population variance
 from the sample  standard deviation of the given one variable data set.  Finding a confidence
interval for a population variance is equivalent to finding a confidence interval for the
population standard deviation and the output box will give confidence intervals for both.  If the
sample size is over 30 a large sample procedure will be used and for a sample size under 30 a small
sample procedure will be employed.  

<P>
The second procedure is to evaluate a hypothesis test testing a user supplied null hypothesis (
given in the form of a target variance or standard deviaiton) against a user supplied alternative
hypothesis.  The P-value of the given data (see below) will be computed and the output box will
indicate whether the results are significant relative to a user supplied level of significance.  As
with the confidence interval procedure if the sample size is over 30 a large sample procedure will
be used and for a sample size under 30 a small sample procedure will be employed.

<P>

<P><P>
<BR>

<P>
<DIV ALIGN="CENTER">
<B>CONFIDENCE INTERVAL FOR THE VARIANCE </B></DIV>
 <BR>
<DIV ALIGN="CENTER">
<B>OF A ONE VARIABLE
DATA SET</B></DIV>

<P><P>
<BR>

<P>
<DIV ALIGN="CENTER">
<B>(1) GENERAL ESTIMATION THEORY</B></DIV>

<P>

<P><P>
<BR>

<P>
Estimates in statistics are most often expressed in terms of <B>confidence intervals</B>. 
Roughly these are intervals of numbers with <B>confidence levels</B> attached indicating the
probability that what is being estimated actually falls within the interval. A formal definiiton
is presented below.  First we give a discussion of the estimation procedure in general.

<P>
In most
standard statistical analyses the parameters that are of most interest are <B>means</B>, <IMG
 WIDTH="14" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img2.gif"
 ALT="$ \mu$">, <B>standard deviations</B> or <B>variances</B>, <IMG
 WIDTH="14" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img3.gif"
 ALT="$ \sigma$"> or <IMG
 WIDTH="21" HEIGHT="17" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.gif"
 ALT="$ \sigma^2$"> and <B>proportions </B> <IMG
 WIDTH="12" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img5.gif"
 ALT="$ p$">.  Eachof
these has a fairly standard statistic  that is used to estimate it.  For means we have <!-- MATH
 $\overline
X$
 -->
<IMG
 WIDTH="19" HEIGHT="17" ALIGN="BOTTOM" BORDER="0"
 SRC="img6.gif"
 ALT="$ \overline
X$">, the sample mean; for standard deviations, <IMG
 WIDTH="12" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img7.gif"
 ALT="$ s$">, the sample standard deviation; and for
proportions <IMG
 WIDTH="12" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img5.gif"
 ALT="$ p$">, the sample proportion <!-- MATH
 $\frac{x}{n}$
 -->
<IMG
 WIDTH="16" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img8.gif"
 ALT="$ \frac{x}{n}$">, where <IMG
 WIDTH="14" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img9.gif"
 ALT="$ n$"> is the number of items observed
and <IMG
 WIDTH="13" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img10.gif"
 ALT="$ x$"> is the number of items observed of the characteristic of interest.  Each of these
statistics is called an <B>estimator</B> for the corresponding parameter; hence <!-- MATH
 $\overline{X}$
 -->
<IMG
 WIDTH="19" HEIGHT="17" ALIGN="BOTTOM" BORDER="0"
 SRC="img11.gif"
 ALT="$ \overline{X}$"> is an
estimator for <IMG
 WIDTH="14" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img2.gif"
 ALT="$ \mu$">,<IMG
 WIDTH="12" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img7.gif"
 ALT="$ s$"> is an estimator for <IMG
 WIDTH="14" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img3.gif"
 ALT="$ \sigma$"> and  <IMG
 WIDTH="12" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img5.gif"
 ALT="$ p$"> is an estimator for <IMG
 WIDTH="12" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img5.gif"
 ALT="$ p$">.  In general
if <IMG
 WIDTH="12" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img12.gif"
 ALT="$ \theta$"> (theta) stands for a parameter, (it is no harm to think of this as either <IMG
 WIDTH="28" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img13.gif"
 ALT="$ \mu,s$"> or
<IMG
 WIDTH="12" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img5.gif"
 ALT="$ p$">), then <IMG
 WIDTH="4" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img14.gif"
 ALT="$ \th$"> will stand for an estimator for <IMG
 WIDTH="12" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img12.gif"
 ALT="$ \theta$">.  Any particular value of an estimator is
called a <B>point estimate</B> for the corresponding parameter.  

<P>
In general, in statistics we do not use point estimates.  There is no confidence in a point
estimate and in most cases the probability that a point estimate is correct is zero.   Rather 
<B>interval estimates</B> are used.  Interval estimates are ranges of numbers which hopefully contain
the parameter we are trying to estimate.  For example if we are trying to estimate the mean
completion time for the surgical procedure of the last section, 151 minutes would be a
point estimate.  A typical interval estimate might be 143 to 159 minutes.  In most cases we
use a special type of interval estimate called a <B>confidence interval estimate</B> or <B>confidence interval</B>. We will give a formal definition below but roughly a confidence
interval estimate for a parameter is an interval estimate with a confidence level
attached.  The confidence level gives the probability that the parameter being estimated
actually falls within the interval.

<P><P>
<BR>

<P>
EXAMPLE
Suppose that a 95% confidence interval for the mean completion time of
the surgical procedure is given by 143 minutes to 159 minutes.  This is interpreted in the
following manner.  The true mean completion time is a number.  There is a 95% probability
that it falls in the interval 143 to 159.

<P><P>
<BR>

<P>
Notice that in using a confidence interval estimate there are two concepts of how good this
estimate is, <B>confidence</B> and <B>accuracy</B>.  The confidence of the estimate is given by the
confidence level while the accuracy is given by the width of the interval.  A narrow interval
indicates greater accuracy than a wider interval.  On an intuitive level it is clear that these two
ideas are <B>inversely related</B>, that is for fixed sample size raising the confidence lowers the
accuracy and vice versa.  We will see this computationally in section 5.4.  However we note that if
we want a given confidence and wish to improve the accuracy we must take a larger sample size.  In
the real world this translates into cost and often the sample size chosen is a compromise between
what the theory requires and what the budget of the study dictates.

<P>
If <IMG
 WIDTH="12" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img12.gif"
 ALT="$ \theta$"> is a parameter for a population <IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img15.gif"
 ALT="$ P$"> and <IMG
 WIDTH="4" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img14.gif"
 ALT="$ \th$"> is an estimator for it, then as one goes
from random sample to random sample from <IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img15.gif"
 ALT="$ P$"> the values of <IMG
 WIDTH="4" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img14.gif"
 ALT="$ \th$"> will vary.  Hence <IMG
 WIDTH="4" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img14.gif"
 ALT="$ \th$"> has its own
distribution of values over all possible samples taken from <IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img15.gif"
 ALT="$ P$"> (we assume here the same
sample size in each case).  This is called the <B>sampling distribution</B> of the
estimator <IMG
 WIDTH="4" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img14.gif"
 ALT="$ \th$">.  Hence for a given sample size <IMG
 WIDTH="14" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img9.gif"
 ALT="$ n$"> and a given population <IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img15.gif"
 ALT="$ P$"> with mean <IMG
 WIDTH="14" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img2.gif"
 ALT="$ \mu$"> there
will be a sampling distribution for <IMG
 WIDTH="4" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img16.gif"
 ALT="$ \X$">, consisting of all possible sample means of
samples of size <IMG
 WIDTH="14" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img9.gif"
 ALT="$ n$"> drawn from <IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img15.gif"
 ALT="$ P$">.  Similarly there will be a sampling distribution
for the sample standard deviation <IMG
 WIDTH="12" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img7.gif"
 ALT="$ s$"> and a sampling distribution for the sample proportion 
<IMG
 WIDTH="12" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img5.gif"
 ALT="$ p$">.  The sampling distribution of an estimator <IMG
 WIDTH="4" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img14.gif"
 ALT="$ \th$"> will have its own mean and own standard
deviation.  We will denote these by <IMG
 WIDTH="15" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img17.gif"
 ALT="$ \mu_{\th}$"> and <!-- MATH
 $\sigma_{\th}$
 -->
<IMG
 WIDTH="14" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img18.gif"
 ALT="$ \sigma_{\th}$">.

<P>
<!-- MATH
 \begin{displaymath}
\mu_{\th} = \text{ mean of the sampling distribution of } \th \text { and }
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="31" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img19.gif"
 ALT="$\displaystyle \mu_{\th} =$">&nbsp; &nbsp; mean of the sampling distribution of <IMG
 WIDTH="4" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img20.gif"
 ALT="$\displaystyle \th$"><IMG
 WIDTH="30" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img21.gif"
 ALT="$\displaystyle \text { and }$">
</DIV><P></P>
<!-- MATH
 \begin{displaymath}
\sigma_{\th} = \text{ standard deviation of the sampling distribution of } \th .
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="31" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img22.gif"
 ALT="$\displaystyle \sigma_{\th} =$">&nbsp; &nbsp; standard deviation of the sampling distribution of <IMG
 WIDTH="8" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img23.gif"
 ALT="$\displaystyle \th .$">
</DIV><P></P>

<P>
If <!-- MATH
 $\mu_{\th} = \theta$
 -->
<IMG
 WIDTH="44" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img24.gif"
 ALT="$ \mu_{\th} = \theta$">, that is the mean of the sampling distribution is equal to the
parameter it is supposed to estimate, then <IMG
 WIDTH="4" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img14.gif"
 ALT="$ \th$"> is called an <B>unbiased estimator</B> for
<IMG
 WIDTH="12" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img12.gif"
 ALT="$ \theta$">.  In general <!-- MATH
 $\sigma_{\th}$
 -->
<IMG
 WIDTH="14" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img18.gif"
 ALT="$ \sigma_{\th}$"> is called the <B>standard error</B> of the estimator.

<P>
We examine these ideas relative to sample means.

<P>
For any population with mean <IMG
 WIDTH="14" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img2.gif"
 ALT="$ \mu$"> and standard deviation <IMG
 WIDTH="14" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img3.gif"
 ALT="$ \sigma$"> the sample mean <IMG
 WIDTH="4" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img16.gif"
 ALT="$ \X$"> is an
unbiased estimator for <IMG
 WIDTH="14" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img2.gif"
 ALT="$ \mu$">.  This means that <!-- MATH
 $\mu_{\th} = \mu$
 -->
<IMG
 WIDTH="45" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img25.gif"
 ALT="$ \mu_{\th} = \mu$"> where <IMG
 WIDTH="15" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img17.gif"
 ALT="$ \mu_{\th}$"> is
the mean of the sampling distribution of <IMG
 WIDTH="4" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img16.gif"
 ALT="$ \X$">.   Further the <B>standard error of the mean</B> is
given by <!-- MATH
 \begin{displaymath}
\sigma_{\X} = \frac{\sigma}{\sqrt{n}}.
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="66" HEIGHT="43" ALIGN="MIDDLE" BORDER="0"
 SRC="img26.gif"
 ALT="$\displaystyle \sigma_{\X} = \frac{\sigma}{\sqrt{n}}.$">
</DIV><P></P>
It follows that for any population the sample
means vary much less than the original population (notice that we are dividing by <IMG
 WIDTH="27" HEIGHT="33" ALIGN="MIDDLE" BORDER="0"
 SRC="img27.gif"
 ALT="$ \sqrt{n}$"> in
finding the standard deviation of the sampling distribution for <IMG
 WIDTH="4" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img16.gif"
 ALT="$ \X$">).

<P><P>
<BR>

<P>
EXAMPLE 
Suppose the discussed surgical procedure has a mean of <IMG
 WIDTH="59" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img28.gif"
 ALT="$ \mu = 150$"> and a
standard deviation of <!-- MATH
 $\sigma = 12$
 -->
<IMG
 WIDTH="51" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img29.gif"
 ALT="$ \sigma = 12$">.  What is the mean and standard deviation of the sampling
distribution of <IMG
 WIDTH="4" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img16.gif"
 ALT="$ \X$"> for samples of size 25.

<P>
The mean of the sampling distribution is the same as the original mean.  Therefore <!-- MATH
 $\mu_{\X} =
\mu = 150$
 -->
<IMG
 WIDTH="90" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img30.gif"
 ALT="$ \mu_{\X} =
\mu = 150$">.  The standard deviation of the sampling distribution or the standard error is the
original standard deviation divided by the squareroot of the sample size.  Therefore
<!-- MATH
 \begin{displaymath}
\sigma_{\X} = \frac{\sigma}{\squareroot{n}} = \frac{12}{5} = 2.4.
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="136" HEIGHT="49" ALIGN="MIDDLE" BORDER="0"
 SRC="img31.gif"
 ALT="$\displaystyle \sigma_{\X} = \frac{\sigma}{\squareroot{n}} = \frac{12}{5} = 2.4.$">
</DIV><P></P>

<P><P>
<BR>

<P>
The idea of an estimator and its sampling distribution is used to give a formal definition of a
confidence interval. Suppose <IMG
 WIDTH="4" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img14.gif"
 ALT="$ \th$"> is an estimator for <IMG
 WIDTH="12" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img12.gif"
 ALT="$ \theta$"> and <!-- MATH
 $h(\th),g(\th)$
 -->
<IMG
 WIDTH="53" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img32.gif"
 ALT="$ h(\th),g(\th)$"> are
functions of <IMG
 WIDTH="4" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img14.gif"
 ALT="$ \th$"> with <!-- MATH
 $h(\th) < g(\th)$
 -->
<IMG
 WIDTH="67" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img33.gif"
 ALT="$ h(\th) &lt; g(\th)$"> for all values of <IMG
 WIDTH="4" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img14.gif"
 ALT="$ \th$">.  Then <!-- MATH
 $[h(\th),g(\th)]$
 -->
<IMG
 WIDTH="62" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img34.gif"
 ALT="$ [h(\th),g(\th)]$"> forms
a <B>random interval</B>, that is an interval of numbers which arises randomly.  If for some
value <IMG
 WIDTH="14" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.gif"
 ALT="$ \alpha$"> we have that <!-- MATH
 \begin{displaymath}
Prob\{h(\th) \le \theta \le g(\th)\} = \alpha,
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="183" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img36.gif"
 ALT="$\displaystyle Prob\{h(\th) \le \theta \le g(\th)\} = \alpha,$">
</DIV><P></P>
then
<!-- MATH
 $[h(\th),g(\th)]$
 -->
<IMG
 WIDTH="62" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img34.gif"
 ALT="$ [h(\th),g(\th)]$"> is called an <IMG
 WIDTH="14" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.gif"
 ALT="$ \alpha$">%-<B>confidence interval for </B><IMG
 WIDTH="12" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img12.gif"
 ALT="$ \theta$">.  This means that
in repeated sampling there is a probability of <IMG
 WIDTH="14" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.gif"
 ALT="$ \alpha$"> that the random interval <!-- MATH
 $[h(\th),g(\th)]$
 -->
<IMG
 WIDTH="62" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img34.gif"
 ALT="$ [h(\th),g(\th)]$">
will contain the parameter <IMG
 WIDTH="12" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img12.gif"
 ALT="$ \theta$">.  For a particular value of <IMG
 WIDTH="4" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img14.gif"
 ALT="$ \th$"> we get a particular interval
and this gives a <B>confidence interval estimate</B> for <IMG
 WIDTH="12" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img12.gif"
 ALT="$ \theta$">.

<P>
Summarizing all this we have that an <!-- MATH
 $\alpha  \%$
 -->
<IMG
 WIDTH="28" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img37.gif"
 ALT="$ \alpha \%$">-<B>confidence interval</B> for a paramter <IMG
 WIDTH="12" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img12.gif"
 ALT="$ \theta$">
is a random interval <!-- MATH
 $[h(\th),g(\th)]$
 -->
<IMG
 WIDTH="62" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img34.gif"
 ALT="$ [h(\th),g(\th)]$">, where <IMG
 WIDTH="4" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img14.gif"
 ALT="$ \th$"> is an estimator of <IMG
 WIDTH="12" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img12.gif"
 ALT="$ \theta$"> and
<!-- MATH
 $h(\th),g(\th)$
 -->
<IMG
 WIDTH="53" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img32.gif"
 ALT="$ h(\th),g(\th)$"> are functions of <IMG
 WIDTH="4" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img14.gif"
 ALT="$ \th$"> such that
<!-- MATH
 \begin{displaymath}
Prob\{h(\th) \le \theta \le g(\th)\} = \alpha.
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="183" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img38.gif"
 ALT="$\displaystyle Prob\{h(\th) \le \theta \le g(\th)\} = \alpha.$">
</DIV><P></P>

<P>

<P><P>
<BR>

<P>
<DIV ALIGN="CENTER">
<B>(2) ESTIMATION OF VARIANCES AND STANDARD DEVIATIONS </B></DIV>

<P>

<P><P>
<BR>

<P>
We now look at the particular case where the parameter of interest is the population variance
<IMG
 WIDTH="21" HEIGHT="17" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.gif"
 ALT="$ \sigma^2$"> and the estimator is the sample variance <IMG
 WIDTH="19" HEIGHT="17" ALIGN="BOTTOM" BORDER="0"
 SRC="img39.gif"
 ALT="$ s^2$">.  Estimating the variance <IMG
 WIDTH="21" HEIGHT="17" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.gif"
 ALT="$ \sigma^2$"> is
equivalent to estimating the standard deviation <IMG
 WIDTH="14" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img3.gif"
 ALT="$ \sigma$">.  As with the estimation procedures for
population means the procedures used with variances are separated into small and large sample
procedures.

<P>
Crucial to estiamtion procedures for variances is the <B>chi-square distribution</B>. If <IMG
 WIDTH="14" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img9.gif"
 ALT="$ n$"> is a
positive integer a <B>chi-square distribution with n degrees of freedom</B> is a continuous
distribution whose density curve has the equation <!-- MATH
 \begin{displaymath}
f(x) = C(n) x^{\frac{n}{2} -1}e^{-x/2}
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="166" HEIGHT="37" ALIGN="MIDDLE" BORDER="0"
 SRC="img40.gif"
 ALT="$\displaystyle f(x) = C(n) x^{\frac{n}{2} -1}e^{-x/2}$">
</DIV><P></P>
where <IMG
 WIDTH="39" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img41.gif"
 ALT="$ C(n)$"> is a constant depending on <IMG
 WIDTH="14" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img9.gif"
 ALT="$ n$"> and <IMG
 WIDTH="42" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img42.gif"
 ALT="$ x &gt; 0$">.  As with  t-distributions there is a
chi-square distribution for each positive integer <IMG
 WIDTH="14" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img9.gif"
 ALT="$ n$">. The integer <IMG
 WIDTH="14" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img9.gif"
 ALT="$ n$"> that it depends upon is called
its <B>degrees of freedom</B> abbreviated d.f..  In distinction to the t-distributions the
chi-square distributions are not symmetric.

<P>
There are tabled values listed for the chi-square distribution
which put given percentages in the tails for given degrees of freedom. Thus a tail entry given by
<!-- MATH
 $\chi^2_{\alpha,n}$
 -->
<IMG
 WIDTH="35" HEIGHT="33" ALIGN="MIDDLE" BORDER="0"
 SRC="img43.gif"
 ALT="$ \chi^2_{\alpha,n}$"> is the value which puts <IMG
 WIDTH="28" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img37.gif"
 ALT="$ \alpha \%$"> in the right hand tail for a
chi-square distribution with <IMG
 WIDTH="14" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img9.gif"
 ALT="$ n$"> degrees of freedom.  For example the value for <!-- MATH
 $\chi^2_{.025,8} =
17.535$
 -->
<IMG
 WIDTH="113" HEIGHT="33" ALIGN="MIDDLE" BORDER="0"
 SRC="img44.gif"
 ALT="$ \chi^2_{.025,8} =
17.535$">.  This indicates that for a chi-square distribution with 8 d.f. the value 17.535 has 2.5% to
the right of it.  In MAGNUSSTAT the appropriate chi-square values for estimation are computed
automatically.  

<P>
The chi-square distribution plays a role in the estimation of standard deviations through the
following fundamental result.

<P>
Sampling Distribution of <IMG
 WIDTH="19" HEIGHT="17" ALIGN="BOTTOM" BORDER="0"
 SRC="img39.gif"
 ALT="$ s^2$"> If <IMG
 WIDTH="19" HEIGHT="17" ALIGN="BOTTOM" BORDER="0"
 SRC="img39.gif"
 ALT="$ s^2$"> is the sample variance based on <IMG
 WIDTH="14" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img9.gif"
 ALT="$ n$">
observations from a normal population with standard deviation <IMG
 WIDTH="14" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img3.gif"
 ALT="$ \sigma$"> then 
<!-- MATH
 \begin{displaymath}
\chi^2 = \frac{(n-1)s^2}{\sigma^2}
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="110" HEIGHT="55" ALIGN="MIDDLE" BORDER="0"
 SRC="img45.gif"
 ALT="$\displaystyle \chi^2 = \frac{(n-1)s^2}{\sigma^2}$">
</DIV><P></P>
has a chi-square distribution with <IMG
 WIDTH="41" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img46.gif"
 ALT="$ n-1$"> degrees of freedom.

<P>
Notice that this result is in terms of the variances.  However estimating variances is
equivalent to estimating standard deviations. Using this result we can derive a <B>confidence interval</B> for <IMG
 WIDTH="21" HEIGHT="17" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.gif"
 ALT="$ \sigma^2$"> and hence for <IMG
 WIDTH="14" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img3.gif"
 ALT="$ \sigma$"> when sampling is done from a normal
population. 

<P>
For a given <IMG
 WIDTH="14" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.gif"
 ALT="$ \alpha$">, find the chi-square values <!-- MATH
 $\chi^2_{\alpha/2}$
 -->
<IMG
 WIDTH="36" HEIGHT="33" ALIGN="MIDDLE" BORDER="0"
 SRC="img47.gif"
 ALT="$ \chi^2_{\alpha/2}$"> and <!-- MATH
 $\chi^2_{1-\alpha/2}$
 -->
<IMG
 WIDTH="52" HEIGHT="33" ALIGN="MIDDLE" BORDER="0"
 SRC="img48.gif"
 ALT="$ \chi^2_{1-\alpha/2}$"> so
that for a chi square distribution with the given degrees of freedom <IMG
 WIDTH="30" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img49.gif"
 ALT="$ \alpha/2$">% is in the right
hand tail and <IMG
 WIDTH="30" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img49.gif"
 ALT="$ \alpha/2$">% is in the left hand tail.  The reason we need two different values is that
the chi-square distribution is not symmetrical.   We indicate this is figure 1. 

<P>

<P></P>

<DIV ALIGN="CENTER">
<IMG
 WIDTH="336" HEIGHT="195" ALIGN="MIDDLE" BORDER="0"
 SRC="Anal_Var_1.gif"
>
</DIV><P></P>


<P></P>
<DIV ALIGN="CENTER">
Figure 1 Chi-Square Confidence Coefficients</DIV>

<P><P>
<BR>

<P>
From the chi-square distribution and the way we chose the chi-square values we have the following
inequality  on chi-square values occurring <IMG
 WIDTH="14" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.gif"
 ALT="$ \alpha$">% of the time
<!-- MATH
 \begin{displaymath}
\chi^2_{1-\alpha/2} \le \chi^2 \le \chi^2_{\alpha/2} .
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="148" HEIGHT="35" ALIGN="MIDDLE" BORDER="0"
 SRC="img50.gif"
 ALT="$\displaystyle \chi^2_{1-\alpha/2} \le \chi^2 \le \chi^2_{\alpha/2} .$">
</DIV><P></P>
We can apply the  sampling distribution result to the chi-square value
<!-- MATH
 \begin{displaymath}
\chi^2 = \frac{(n-1)s^2}{\sigma^2}
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="110" HEIGHT="55" ALIGN="MIDDLE" BORDER="0"
 SRC="img45.gif"
 ALT="$\displaystyle \chi^2 = \frac{(n-1)s^2}{\sigma^2}$">
</DIV><P></P>
to get the following inequality which must occur <IMG
 WIDTH="14" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.gif"
 ALT="$ \alpha$">% of the time
<!-- MATH
 \begin{displaymath}
\chi^2_{1-\alpha/2} \le \frac{(n-1)s^2}{\sigma^2} \le \chi^2_{\alpha/2}  \tag 1
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="202" HEIGHT="55" ALIGN="MIDDLE" BORDER="0"
 SRC="img51.gif"
 ALT="$\displaystyle \chi^2_{1-\alpha/2} \le \frac{(n-1)s^2}{\sigma^2} \le \chi^2_{\alpha/2} \tag 1$">
</DIV><P></P>
Solving this inequality for <IMG
 WIDTH="21" HEIGHT="17" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.gif"
 ALT="$ \sigma^2$">, the value which we are trying to estimate, we get the
following inequality which must occur <IMG
 WIDTH="14" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.gif"
 ALT="$ \alpha$">% of the time.
<!-- MATH
 \begin{displaymath}
\frac{(n-1)s^2}{\chi^2_{\alpha/2}} \le \sigma^2 \le \frac{(n-1)s^2}{\chi^2_{1-\alpha/2}}
\tag 2
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="207" HEIGHT="55" ALIGN="MIDDLE" BORDER="0"
 SRC="img52.gif"
 ALT="$\displaystyle \frac{(n-1)s^2}{\chi^2_{\alpha/2}} \le \sigma^2 \le \frac{(n-1)s^2}{\chi^2_{1-\alpha/2}}
\tag 2$">
</DIV><P></P>

<P>
The inequality in (2) defines a random interval containing <IMG
 WIDTH="21" HEIGHT="17" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.gif"
 ALT="$ \sigma^2$"> which must occur <IMG
 WIDTH="14" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.gif"
 ALT="$ \alpha$">%
of the time and thus defines an <IMG
 WIDTH="14" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.gif"
 ALT="$ \alpha$">-percent confidence interval for <IMG
 WIDTH="21" HEIGHT="17" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.gif"
 ALT="$ \sigma^2$">.  Particular
values for the variables will give a confidence interval estimate. Taking the square root of these
values will give a confidence interval for <IMG
 WIDTH="14" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img3.gif"
 ALT="$ \sigma$">.

<P>
Confidence Intervals for <IMG
 WIDTH="21" HEIGHT="17" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.gif"
 ALT="$ \sigma^2$"> If <IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img15.gif"
 ALT="$ P$"> is a normal population with standard
deviation <IMG
 WIDTH="14" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img3.gif"
 ALT="$ \sigma$"> then an <IMG
 WIDTH="14" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.gif"
 ALT="$ \alpha$">% confidence interval for <IMG
 WIDTH="21" HEIGHT="17" ALIGN="BOTTOM" BORDER="0"
 SRC="img4.gif"
 ALT="$ \sigma^2$"> is given by
<!-- MATH
 \begin{displaymath}
\frac{(n-1)s^2}{\chi^2_{\alpha/2}} \le \sigma^2 \le \frac{(n-1)s^2}{\chi^2_{1-\alpha/2}}
\tag 2
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="207" HEIGHT="55" ALIGN="MIDDLE" BORDER="0"
 SRC="img52.gif"
 ALT="$\displaystyle \frac{(n-1)s^2}{\chi^2_{\alpha/2}} \le \sigma^2 \le \frac{(n-1)s^2}{\chi^2_{1-\alpha/2}}
\tag 2$">
</DIV><P></P>
where 
<!-- MATH
 \begin{displaymath}
s = \text { sample standard deviation}
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="28" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img53.gif"
 ALT="$\displaystyle s =$"><IMG
 WIDTH="185" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img54.gif"
 ALT="$\displaystyle \text { sample standard deviation}$">
</DIV><P></P>
<!-- MATH
 \begin{displaymath}
\chi^2_{\alpha/2},\chi^2_{1-\alpha/2} = \alpha\% \text { confidence coefficients based on n-1 d.f.
}
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="136" HEIGHT="35" ALIGN="MIDDLE" BORDER="0"
 SRC="img55.gif"
 ALT="$\displaystyle \chi^2_{\alpha/2},\chi^2_{1-\alpha/2} = \alpha\%$"><IMG
 WIDTH="290" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img56.gif"
 ALT="$\displaystyle \text { confidence coefficients based on n-1 d.f.
}$">
</DIV><P></P> <!-- MATH
 \begin{displaymath}
n = \text { sample size }.
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="30" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img57.gif"
 ALT="$\displaystyle n =$"><IMG
 WIDTH="87" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img58.gif"
 ALT="$\displaystyle \text { sample size }. $">
</DIV><P></P>

<P>
EXAMPLE 

A study was done to determine the mean time to toleration of solid food after a stomach surgery.  A
random sample of 16 patients had a sample mean of 6.2 days with a sample standard
deviation of 1.2 days.  Determine a 95%  confidence interval estimate for the  standard
deviation of time.

<P>
Here <IMG
 WIDTH="51" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img59.gif"
 ALT="$ n = 16$"> Assuming that the time follows a
normal distribution we can apply the above results.  First we must find the 95% 
chi-square confidence coefficients. Since a 95% interval will leave a total of 5% in the tails
there is 2.5% in each tail.  There are 16 observations so 15 d.f.  Therefore the appropriate
chi-square confidence coefficients are

<P>
<!-- MATH
 \begin{displaymath}
\chi^2_{.975,15} = 6.262 \text{ and } \chi^2_{.025,15} = 27.488.
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="112" HEIGHT="35" ALIGN="MIDDLE" BORDER="0"
 SRC="img60.gif"
 ALT="$\displaystyle \chi^2_{.975,15} = 6.262$">&nbsp; &nbsp; and <IMG
 WIDTH="124" HEIGHT="35" ALIGN="MIDDLE" BORDER="0"
 SRC="img61.gif"
 ALT="$\displaystyle \chi^2_{.025,15} = 27.488.$">
</DIV><P></P>

<P>
The remaining computed information is that <IMG
 WIDTH="53" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img62.gif"
 ALT="$ s = 1.2$"> Therefore the confidence interval estimate is
<!-- MATH
 \begin{displaymath}
\frac{(15)1.2^2}{27.488} \le \sigma^2 \le \frac{(15)1.2^2}{6.262}
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="182" HEIGHT="55" ALIGN="MIDDLE" BORDER="0"
 SRC="img63.gif"
 ALT="$\displaystyle \frac{(15)1.2^2}{27.488} \le \sigma^2 \le \frac{(15)1.2^2}{6.262}$">
</DIV><P></P>
<!-- MATH
 \begin{displaymath}
.786 \le \sigma^2 \le 3.449
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="128" HEIGHT="35" ALIGN="MIDDLE" BORDER="0"
 SRC="img64.gif"
 ALT="$\displaystyle .786 \le \sigma^2 \le 3.449$">
</DIV><P></P>
Taking the squareroots of these values will give a 95% confidence interval for <IMG
 WIDTH="14" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img3.gif"
 ALT="$ \sigma$">
<!-- MATH
 \begin{displaymath}
.887 \le \sigma \le 1.857.
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="125" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img65.gif"
 ALT="$\displaystyle .887 \le \sigma \le 1.857.$">
</DIV><P></P>

<P>
Therefore a 95% confidence interval for the standard deviation of time to tolerate solid food is
.887 days to 1.857 days.

<P><P>
<BR>

<P>
There is a  central limit theorem for the chi-square distribution from which a large sample
confidence interval for <IMG
 WIDTH="14" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img3.gif"
 ALT="$ \sigma$"> can be derived. For large sample sizes <IMG
 WIDTH="14" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img9.gif"
 ALT="$ n$"> from a normal
distribution we obtain the following:

<P>
Large Sample Sampling Distribution of <IMG
 WIDTH="12" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img7.gif"
 ALT="$ s$"> If <IMG
 WIDTH="12" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img7.gif"
 ALT="$ s$"> is the sample standard deviation based on
<IMG
 WIDTH="14" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img9.gif"
 ALT="$ n$"> observations from a normal population with standard deviation <IMG
 WIDTH="14" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img3.gif"
 ALT="$ \sigma$"> then for large <IMG
 WIDTH="14" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img9.gif"
 ALT="$ n$"> 
<!-- MATH
 \begin{displaymath}
z = \frac{s - \sigma}{\frac{\sigma}{\sqrt{2n}}}
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="74" HEIGHT="47" ALIGN="MIDDLE" BORDER="0"
 SRC="img66.gif"
 ALT="$\displaystyle z = \frac{s - \sigma}{\frac{\sigma}{\sqrt{2n}}}$">
</DIV><P></P>
has an approximate normal distribution.

<P>
Using this we can derive a large sample confidence interval for <IMG
 WIDTH="14" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img3.gif"
 ALT="$ \sigma$"> using confidence
coefficients from the normal distribution.

<P>
Large Sample Confidence Intervals for <IMG
 WIDTH="14" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img3.gif"
 ALT="$ \sigma$"> If <IMG
 WIDTH="16" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img15.gif"
 ALT="$ P$"> is a normal population with
standard deviation <IMG
 WIDTH="14" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img3.gif"
 ALT="$ \sigma$"> then a large sample <IMG
 WIDTH="14" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.gif"
 ALT="$ \alpha$">% confidence interval for <IMG
 WIDTH="14" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img3.gif"
 ALT="$ \sigma$"> is
given by <!-- MATH
 \begin{displaymath}
\frac{s}{1+\frac{z_{\alpha/2}}{\sqrt{2n}}} \le \sigma \le
 \frac{s}{1-\frac{z_{\alpha/2}}{\sqrt{2n}}}
\tag 3
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="185" HEIGHT="49" ALIGN="MIDDLE" BORDER="0"
 SRC="img67.gif"
 ALT="$\displaystyle \frac{s}{1+\frac{z_{\alpha/2}}{\sqrt{2n}}} \le \sigma \le
\frac{s}{1-\frac{z_{\alpha/2}}{\sqrt{2n}}}
\tag 3$">
</DIV><P></P>
where 
<!-- MATH
 \begin{displaymath}
z_{\alpha/2} = \alpha\% \text { normal confidence coefficient
}
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="78" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img68.gif"
 ALT="$\displaystyle z_{\alpha/2} = \alpha\%$"><IMG
 WIDTH="217" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img69.gif"
 ALT="$\displaystyle \text { normal confidence coefficient
}$">
</DIV><P></P>

<P>

<P><P>
<BR>

<P>
EXAMPLE 

Suppose in the toleration of solid food study there was a 
random sample of 60 patients an there was a standard deviation of 1.2 days. Determine a 95%
confidence interval for the population standard devaition.  

<P>
Here <IMG
 WIDTH="51" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img70.gif"
 ALT="$ n = 60$">, so assuming that the time
follows a normal distribution we can apply the large sample results. We have <!-- MATH
 $s = 1.2, n = 60$
 -->
<IMG
 WIDTH="107" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img71.gif"
 ALT="$ s = 1.2, n = 60$"> and
an appropriate 95% normal confidence coefficient is 1.96.  Therefore the computed confidence
interval estimate is

<P>
<!-- MATH
 \begin{displaymath}
\frac{1.2}{1 + \frac{1.96}{\sqrt{120}}} \le \sigma \le \frac{1.2}{1 - \frac{1.96}{\sqrt{120}}}
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="185" HEIGHT="49" ALIGN="MIDDLE" BORDER="0"
 SRC="img72.gif"
 ALT="$\displaystyle \frac{1.2}{1 + \frac{1.96}{\sqrt{120}}} \le \sigma \le \frac{1.2}{1 - \frac{1.96}{\sqrt{120}}}$">
</DIV><P></P>
<!-- MATH
 \begin{displaymath}
1.018 \le \sigma \le 1.461
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="129" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img73.gif"
 ALT="$\displaystyle 1.018 \le \sigma \le 1.461$">
</DIV><P></P>

<P>
Therefore a 95% confidence interval for the standard deviation of time to tolerate solid food is
1.018 days to 1.461 days.

<P>
Notice that this is a more accurate estimate than the one derived in the first example as to be
expected, since a larger sample size was used. 

<P>

<P><P>
<BR>

<P>
<DIV ALIGN="CENTER">
<B>HYPOTHESIS TESTING FOR THE MEAN </B></DIV>
 <BR>
<DIV ALIGN="CENTER">
<B>OF A ONE VARIABLE DATA
SET</B></DIV>

<P><P>
<BR>

<P>
<DIV ALIGN="CENTER">
<B>(1) GENERAL THEORY OF HYPOTHESIS TESTING</B></DIV>

<P>

<P><P>
<BR>

<P>
In that <B>estimation theory</B> we considered sampling from
a population and then estimating parameter values from the computed sample information.  We now
discuss <B>statistical testing</B> or <B>hypothesis testing</B>.  Much of the theoretical framework is
the same as in estimation theory but the viewpoint is different.  In hypothesis testing we begin with
a claim or <B>hypothesis</B> about a population parameter and then test this claim by looking at sample
information.

<P>
Suppose that standard guidelines say that the average time to complete a certain surgical
procedure is 2 hours or 120 minutes. We take the claim of an average of 120 minutes as a <B>hypothesis</B> about the true population mean and we wish to test whether this is correct or
not. Suppose further that a random sample of 25 of these surgical procedures had an average (sample
average) completion time of 151 minutes.  Then the observed evidence is that it actually takes longer
than 120 minutes on average.  Of course the difference between the theoretical avergae of 120
minutes and the observed value of 151 minutes may be soley due to random variation.  If  we use
the computed sample mean of 151 minutes as evidence that either the claim that the population mean
is 120 is correct or that the claim is too low this is an example of a <B>hypothesis testing
procedure</B>.  Essentially here we are looking at whether the observed value, 151 minutes, is far
enough away from the hypothesized mean of 120 minutes to be evidence that 120 is too low.  The
criteria used to determine in a scientific manner whether it is far enough away will be discussed
below.

<P>
What is crucial in statistical hypothesis testing is that the general procedure is not to prove
the hypothesis but rather <B>to attempt to disprove the hypothesis</B>.  For this reason the
hypotheses that we test in statistics are called <B>null hypotheses</B> because we are trying to
null them or negate them.  If we cannot null them or negate them we accept them.  Null hypotheses
are denoted by <IMG
 WIDTH="25" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img74.gif"
 ALT="$ H_0$"> and generally have the form
<!-- MATH
 \begin{displaymath}
H_0: \theta = \theta_0
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="81" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img75.gif"
 ALT="$\displaystyle H_0: \theta = \theta_0$">
</DIV><P></P>
where <IMG
 WIDTH="12" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img12.gif"
 ALT="$ \theta$"> is a parameter and <IMG
 WIDTH="19" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img76.gif"
 ALT="$ \theta_0$"> is a particular value.  

<P>
In the example involving the surgical procedure time the parameter being tested is the population
mean <IMG
 WIDTH="14" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img2.gif"
 ALT="$ \mu$"> and the claim is that this mean is 120 minutes.  Therefore for this test the null
hypothesis is
<!-- MATH
 \begin{displaymath}
H_0: \mu = 120.
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="97" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img77.gif"
 ALT="$\displaystyle H_0: \mu = 120.$">
</DIV><P></P>

<P>
EXAMPLE 6

Suppose we consider two different hospitals A and B and we wish to determine if the average per
patient cost for a given procedure is the same in both hospitals.  If we let <IMG
 WIDTH="24" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img78.gif"
 ALT="$ \mu_A$"> be the average
per patient cost in hospital A and <IMG
 WIDTH="25" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img79.gif"
 ALT="$ \mu_B$"> be the average
per patient cost in hospital B then the parameter being testing is <!-- MATH
 $\mu_A - \mu_B$
 -->
<IMG
 WIDTH="64" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img80.gif"
 ALT="$ \mu_A - \mu_B$"> the difference
of the two means.  The appropriate null hypothesis is then
<!-- MATH
 \begin{displaymath}
H_0:\mu_A - \mu_B = 0
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="127" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img81.gif"
 ALT="$\displaystyle H_0:\mu_A - \mu_B = 0$">
</DIV><P></P>
a difference of 0 indicating no difference between the two hospitals. 

<P><P>
<BR>

<P>
To actually test a given null hypothesis we roughly proceed as follows: for an estimator
statistic <IMG
 WIDTH="4" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img14.gif"
 ALT="$ \th$"> for <IMG
 WIDTH="12" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img12.gif"
 ALT="$ \theta$"> we have a cutoff value <IMG
 WIDTH="11" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img82.gif"
 ALT="$ c$">.  If <IMG
 WIDTH="28" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img83.gif"
 ALT="$ \th &gt;c$"> we reject the null hypothesis
while otherwise we accept it.  Which estimator statistic to use, how the value of <IMG
 WIDTH="11" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img82.gif"
 ALT="$ c$"> is determined
and how to actually carry out the analysis we will now discuss.  

<P>
In testing a null hypothesis <!-- MATH
 $H_0: \theta = \theta_0$
 -->
<IMG
 WIDTH="81" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img84.gif"
 ALT="$ H_0: \theta = \theta_0$"> the idea is to attempt to disprove it or
reject it.  We must therefore have an <B>alternative hypothesis</B>, which we denote by <IMG
 WIDTH="25" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img85.gif"
 ALT="$ H_1$"> to
accept if we do reject <IMG
 WIDTH="25" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img74.gif"
 ALT="$ H_0$">.  The alternative hypothesis can have one of three possible forms:
<!-- MATH
 \begin{displaymath}
H_1: \theta \ne \theta_0
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="81" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img86.gif"
 ALT="$\displaystyle H_1: \theta \ne \theta_0$">
</DIV><P></P>
<!-- MATH
 \begin{displaymath}
H_1: \theta > \theta_0
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="81" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img87.gif"
 ALT="$\displaystyle H_1: \theta &gt; \theta_0$">
</DIV><P></P>
<!-- MATH
 \begin{displaymath}
H_1: \theta < \theta_0.
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="86" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img88.gif"
 ALT="$\displaystyle H_1: \theta &lt; \theta_0.$">
</DIV><P></P>
The first form is called a <B>two-sided alternative</B> while the second two forms are called <B>one-sided alternatives</B>.  Usually the alternative hypothesis is what is really believed to be true in
the test.  The null hypothesis is set up in such a manner so that if it is rejected we arrive at the
appropriate alternative.

<P>
EXAMPLE 

<P>
In the test of surgical time we had the null hypothesis
<!-- MATH
 \begin{displaymath}
H_0:\mu = 120.
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="97" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img77.gif"
 ALT="$\displaystyle H_0: \mu = 120.$">
</DIV><P></P>
The computed evidence is that this figure is too low or equivalently that the true mean is higher. 
Therefore in this case the appropriate alternative is
<!-- MATH
 \begin{displaymath}
H_1: \mu > 120.
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="97" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img89.gif"
 ALT="$\displaystyle H_1: \mu &gt; 120.$">
</DIV><P></P>
This is a one-sided alternative.

<P><P>
<BR>

<P>
Once a null hypothesis and alternative hypothesis are chosen we have the following schematic
situation (figure 1) which contains all the relevant information about statistical testing.

<P>

<P></P>

<DIV ALIGN="CENTER">
<IMG
 WIDTH="336" HEIGHT="195" ALIGN="MIDDLE" BORDER="0"
 SRC="Anal_Var_5.gif"
>
</DIV><P></P>
<DIV ALIGN="CENTER">
Figure 1 Hypothesis Testing</DIV>

<P><P>
<BR>

<P>
A <B>type 1 error</B> is the error of rejecting a null hypothesis when it is really true.  Here we
randomly get a sample which refutes the null hypothesis even though the null hypothesis is true.  The
probability or risk of committing a type 1 error is called the <B>level of significance</B> or
<!-- MATH
 $\bold{\alpha}$
 -->
<IMG
 WIDTH="14" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img90.gif"
 ALT="$ \bold{\alpha}$">-<B>error</B> (alpha error). 
A <B>type 2 error</B> is the error of accepting a null hypothesis when it is really false.  Here we
randomly obtain a sample which backs up the null hypothesis even though the null hypothesis is
false.  The probability or risk of committing a type 1 error is called the  <!-- MATH
 $\bold{\beta}$
 -->
<IMG
 WIDTH="14" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img91.gif"
 ALT="$ \bold{\beta}$">-<B>error</B> (beta error). It is also called the
<B>operating characteristic value</B>.  The probability of not committing a type 2 error {the lower
right hand box} is <IMG
 WIDTH="41" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img92.gif"
 ALT="$ 1- \beta$"> and is called the <B>power of the test</B>.  If there are two possible
tests for a hypothesis the more powerful test is the one with the higher power.  The values of
<IMG
 WIDTH="14" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.gif"
 ALT="$ \alpha$"> and <IMG
 WIDTH="14" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img93.gif"
 ALT="$ \beta$"> are inversely related for a fixed sample size.  That is if there is a small
<IMG
 WIDTH="14" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.gif"
 ALT="$ \alpha$">, that is a small chance of making a type 1 error, there may be a larger <IMG
 WIDTH="14" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img93.gif"
 ALT="$ \beta$">, or a
larger chance of making a type 2 error.  If we wish to maintain a small <IMG
 WIDTH="14" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.gif"
 ALT="$ \alpha$"> and have a smaller
<IMG
 WIDTH="14" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img93.gif"
 ALT="$ \beta$"> we must take a larger sample size.  The relationship between <IMG
 WIDTH="14" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.gif"
 ALT="$ \alpha$"> and <IMG
 WIDTH="14" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img93.gif"
 ALT="$ \beta$"> is
analogous to the relationship between confidence and accuracy in an estimation procedure.

<P>
In setting up a criterion for accepting or rejecting a null hypothesis <IMG
 WIDTH="25" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img74.gif"
 ALT="$ H_0$"> we attempt to set the
level of significance at a predetermined small value.  In most practical testing this value is
either 1% or 5% although any value can be used. For example if a test is conducted at a 5% level of
significance this means that there is only a 5% chance of rejecting the null hypothesis if it is
really true.

<P>
There is a nice analogy between the hypothesis testing framework and the framework of the
criminal justice system in the United States.  When a defendant goes into court the presumption is
innocent until proven guilty.  The burden of proof is all on the prosecution.  Hence the
defendants innocence is a null hypothesis while the alternative is the defendant's guilt.
Therefore we have
<!-- MATH
 \begin{displaymath}
H_O: \text{ Defendant is Inncoent}
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="37" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img94.gif"
 ALT="$\displaystyle H_O:$">&nbsp; &nbsp; Defendant is Inncoent
</DIV><P></P>
<!-- MATH
 \begin{displaymath}
H_1: \text{ Defendant is Guilty}.
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="33" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img95.gif"
 ALT="$\displaystyle H_1:$">&nbsp; &nbsp; Defendant is Guilty<IMG
 WIDTH="8" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img96.gif"
 ALT="$\displaystyle .$">
</DIV><P></P>
Then there is
the following schematic. 

<P>

<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="336" HEIGHT="195" ALIGN="MIDDLE" BORDER="0"
 SRC="Anal_Var_2.gif"
>
</DIV><P></P>

<DIV ALIGN="CENTER">
Figure 2 Legal Analogy</DIV>

<P><P>
<BR>

<P>
Hence in this legal analogy the <IMG
 WIDTH="14" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.gif"
 ALT="$ \alpha$">-error is convicting an inncoent defendant while the
<IMG
 WIDTH="14" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img93.gif"
 ALT="$ \beta$">-error is letting a guilty defendant go free.  Historically the American legal system has
been geared to making <IMG
 WIDTH="14" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.gif"
 ALT="$ \alpha$"> as small as possible.  What must be realized is that this follows
the above theoretical model so that <IMG
 WIDTH="14" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.gif"
 ALT="$ \alpha$"> and <IMG
 WIDTH="14" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img93.gif"
 ALT="$ \beta$"> are inversely related.  In practical terms
this means that anything that is done to make it harder to convict an innocent person will
increase the probability of letting a guilty person go free.  Conversely anything done to make it
harder for a guilty person to go free will increase the probability of convicting an innocent
person.   

<P>
<DIV ALIGN="CENTER">
<B>(2) GENERAL STATISTICAL TESTING PROCEDURE </B></DIV>

<P>
For any statistical hypothesis test there is a five step procedure that is always followed.  What
will differ in this procedure in going from test to test is the type of test statistic used and the
determination of critical regions.  We will go over this procedure, do some examples and then in the
rest of the chapter go over the particular types of tests most relevant to nursing and medical
practice.

<P><P>
<BR>

<P>
The <B>first step</B> in the testing procedure is to <B>formulate the null hypothesis</B> <IMG
 WIDTH="25" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img74.gif"
 ALT="$ H_0$">.  As
explained in section 6.1 this will usually have the form <!-- MATH
 $\theta = \theta_0$
 -->
<IMG
 WIDTH="48" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img97.gif"
 ALT="$ \theta = \theta_0$"> where <IMG
 WIDTH="12" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img12.gif"
 ALT="$ \theta$"> is a
parameter and <IMG
 WIDTH="19" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img76.gif"
 ALT="$ \theta_0$"> is a particular value.  Recall that we are not trying to prove this null
hypothesis but rather to disprove it or reject it.  If we cannot reject it it will be accepted.

<P><P>
<BR>

<P>
The <B>second step</B> in the testing procedure is to <B>formulate the alternative hypothesis</B>
<IMG
 WIDTH="25" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img85.gif"
 ALT="$ H_1$"> which will be accepted if the null hypothesis is rejected.  As explained in the last section
the alternative hypothesis can have one of three possible forms:
<!-- MATH
 \begin{displaymath}
H_1: \theta \ne \theta_0
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="81" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img86.gif"
 ALT="$\displaystyle H_1: \theta \ne \theta_0$">
</DIV><P></P>
<!-- MATH
 \begin{displaymath}
H_1: \theta > \theta_0
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="81" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img87.gif"
 ALT="$\displaystyle H_1: \theta &gt; \theta_0$">
</DIV><P></P>
<!-- MATH
 \begin{displaymath}
H_1: \theta < \theta_0.
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="86" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img88.gif"
 ALT="$\displaystyle H_1: \theta &lt; \theta_0.$">
</DIV><P></P>
The first form is called a <B>two-sided alternative</B> while the second two forms are called <B>one-sided alternatives</B>.  The alternative hypothesis i usually what is really believed in the
test.  The null hypothesis is set up in such a manner so that if it is rejected we arrive at the
appropriate alternative.

<P><P>
<BR>

<P>
The <B>third step</B> in the testing procedure is to choose three things: a <B>level of
significance</B>, a <B>sample size</B> and an <B>appropriate test statistic</B>. 

<P>
The level of
significance is the probability of making a type 1 error, that is the probability of rejecting the
null hypothesis when it is true.  It is chosen to be a small number, usually 1% or 5%, although any
value can be used.  If we reject at 1% value then we are 99% confident that we made the right
decision.

<P>
The appropriate test statistic is a statistic whose sampling distribution depends upon the
parameter being tested.  We wish to find the cutoff value so that the probability of the observed
value of the test statistic is low (less than the level of significance) if the null hypothesis is
false.  How we arrive at appropriate test statistics will be discussed in subsequent sections.

<P><P>
<BR>

<P>
The <B>fourth step</B> in the testing procedure is to determine a <B>rejection region</B> or <B>critical region</B>.  This region will serve as the cutoff for accepting or rejecting the null
hypothesis.  If the observed value of the test statistic falls in the rejection region the null
hypothesis will be rejectedd.  If the observed value of the test statistic doesn't fall in the
rejection region then the null hypothesis will be accepted.  The determination of the critical region
will be based on the level of significance and the sampling distribution of the test statistic and
will be determined so that the probability of a value of the test statistic falling the critical
region is less than the level of significance.  Again we will see how this is done for specific test
statistics in subsequent sections. 
<P><P>
<BR>

<P>
The <B>fifth step</B> and final step in the testing procedure is to obtain sample results and a value
for the test statistic. If the test results are in the rejection region the results are
said to be <B>statistically significant</B> and the null hypothesis <IMG
 WIDTH="25" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img74.gif"
 ALT="$ H_0$"> is rejected in favor of the
alternative <IMG
 WIDTH="25" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img85.gif"
 ALT="$ H_1$">. If the test results are not in the rejection region then we say the results are
<B>not statistically significant</B> and the null hypothesis <IMG
 WIDTH="25" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img74.gif"
 ALT="$ H_0$"> is accepted. 
Thus significant results lead to rejection of the null hypothesis while not significant results lead
to acceptance of the null hypothesis.  

<P>
Another concept is important relative to this fifth step.  The <B>P-value</B> of the test results is
the probability of obtaining a value of the test statistic more unusual that what was obtained,
assuming the null hypothesis is true.  If there is a level of significance <IMG
 WIDTH="14" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.gif"
 ALT="$ \alpha$">, then being in the
rejection region is equivalent to having a P-value less than <IMG
 WIDTH="14" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.gif"
 ALT="$ \alpha$">.  Hence the null hypothesis is
rejected whenever the P-value is less than the given level of significance.  Therefore we have the
following two equivalent rejection criteria:

<P>
<!-- MATH
 $\hphantom{xx}$
 -->
<IMG
 WIDTH="22" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img98.gif"
 ALT="$ \hphantom{xx}$"> (1) The value of the test statistic falls in the rejection region

<P>
<!-- MATH
 $\hphantom{xx}$
 -->
<IMG
 WIDTH="22" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img98.gif"
 ALT="$ \hphantom{xx}$"> (2) The P-value of the test results are lower than the level of significance
<IMG
 WIDTH="14" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.gif"
 ALT="$ \alpha$">.

<P>
The second criteria is important to note since many computer programs print the P-values.  In using
these programs the rejection regions don't have to be determined - just the computed P-values
compared with the given <IMG
 WIDTH="14" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.gif"
 ALT="$ \alpha$">.  
.

<P>
We now summarize the five step procedure and then do several examples.

<P><P>
<BR>

<P>
<DIV ALIGN="CENTER">
<B>FIVE STEP HYPOTHESIS TESTING PROCEDURE</B></DIV>

<P><P>
<BR>
<!-- MATH
 $\hphantom{xx}$
 -->
<IMG
 WIDTH="22" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img98.gif"
 ALT="$ \hphantom{xx}$"> <B>STEP ONE</B>: Formulate the null hypothesis: 
<!-- MATH
 \begin{displaymath}
H_0: \theta = \theta_0
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="81" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img75.gif"
 ALT="$\displaystyle H_0: \theta = \theta_0$">
</DIV><P></P>
where <IMG
 WIDTH="12" HEIGHT="15" ALIGN="BOTTOM" BORDER="0"
 SRC="img12.gif"
 ALT="$ \theta$"> is a parameter and <IMG
 WIDTH="19" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img76.gif"
 ALT="$ \theta_0$"> a particular value.

<P>

<P><P>
<BR>
<!-- MATH
 $\hphantom{xx}$
 -->
<IMG
 WIDTH="22" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img98.gif"
 ALT="$ \hphantom{xx}$"> <B>STEP TWO</B>: Formulate the alternative hypothesis:
<!-- MATH
 \begin{displaymath}
H_1: \theta \ne \theta_0 \text { or}
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="81" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img86.gif"
 ALT="$\displaystyle H_1: \theta \ne \theta_0$"><IMG
 WIDTH="19" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img99.gif"
 ALT="$\displaystyle \text { or}$">
</DIV><P></P>
<!-- MATH
 \begin{displaymath}
H_1: \theta > \theta_0 \text { or}
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="81" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img87.gif"
 ALT="$\displaystyle H_1: \theta &gt; \theta_0$"><IMG
 WIDTH="19" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img99.gif"
 ALT="$\displaystyle \text { or}$">
</DIV><P></P>
<!-- MATH
 \begin{displaymath}
H_1: \theta < \theta_0.
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="86" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img88.gif"
 ALT="$\displaystyle H_1: \theta &lt; \theta_0.$">
</DIV><P></P>

<P><P>
<BR>

<P>
<!-- MATH
 $\hphantom{xx}$
 -->
<IMG
 WIDTH="22" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img98.gif"
 ALT="$ \hphantom{xx}$"> <B>STEP THREE</B>: Choose a <B>level of significance</B> <IMG
 WIDTH="14" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img35.gif"
 ALT="$ \alpha$">, a <B>sample size</B>
<IMG
 WIDTH="14" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img9.gif"
 ALT="$ n$"> and <B>an appropriate test statistic</B>.

<P><P>
<BR>

<P>
<!-- MATH
 $\hphantom{xx}$
 -->
<IMG
 WIDTH="22" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img98.gif"
 ALT="$ \hphantom{xx}$"> <B>STEP FOUR</B>: Based on the sampling distribution of the test statistic and the
chosen level of significance determine a <B>rejection region</B> or <B>critical region</B>.  The
values not in the rejection region are called the <B>acceptance region</B>.

<P><P>
<BR>

<P>
<!-- MATH
 $\hphantom{xx}$
 -->
<IMG
 WIDTH="22" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img98.gif"
 ALT="$ \hphantom{xx}$"> <B>STEP FIVE</B>: Obtain test results and a value for the test statistic.

<P>
<!-- MATH
 $\hphantom{xxxxx}$
 -->
<IMG
 WIDTH="50" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img100.gif"
 ALT="$ \hphantom{xxxxx}$"> (a) If the test results are in the rejection region the results are
said to be <B>statistically significant</B> and the null hypothesis <IMG
 WIDTH="25" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img74.gif"
 ALT="$ H_0$"> is rejected in favor of the
alternative <IMG
 WIDTH="25" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img85.gif"
 ALT="$ H_1$">.  This is equivalent to the P-value of the test results being lower than the level
of significance.

<P>
<!-- MATH
 $\hphantom{xxxxx}$
 -->
<IMG
 WIDTH="50" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img100.gif"
 ALT="$ \hphantom{xxxxx}$"> (b)If the test results are not in the rejection region then we say the results are
<B>not statistically significant</B> and the null hypothesis <IMG
 WIDTH="25" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img74.gif"
 ALT="$ H_0$"> is accepted.  This is equivalent
to the P-value of the results being higher than the level of significance.

<P><P>
<BR>

<P>
EXAMPLE 
 It is claimed that the average production time for a certain
produced item is 26 minutes.  There is some evidence that it actually takes longer.  To test the
claim, 64 items were sampled. A sample average production time of <IMG
 WIDTH="49" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img101.gif"
 ALT="$ \X = 27.5$"> minutes with a
standard deviation of <IMG
 WIDTH="53" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img102.gif"
 ALT="$ s = 4.5$"> minutes was computed.  Is this enough evidence at a 5% level of
significance to reject the claim.

<P>
Here the null hypothesis is <IMG
 WIDTH="51" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img103.gif"
 ALT="$ \mu = 26$"> matching the claim.  We are interested in the fact that it
actually takes longer so the alternative is <IMG
 WIDTH="51" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img104.gif"
 ALT="$ \mu &gt; 26$">.  This is a one-sided alternative.  Hence we
have
<!-- MATH
 \begin{displaymath}
H_0: \mu = 26
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="85" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img105.gif"
 ALT="$\displaystyle H_0: \mu = 26$">
</DIV><P></P>
<!-- MATH
 \begin{displaymath}
H_1: \mu > 26
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="85" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img106.gif"
 ALT="$\displaystyle H_1: \mu &gt; 26$">
</DIV><P></P>
This takes care of steps one and two.

<P>
The sample size is <IMG
 WIDTH="51" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img107.gif"
 ALT="$ n = 64$"> while the chosen level of significance is <!-- MATH
 $\alpha = .05$
 -->
<IMG
 WIDTH="56" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img108.gif"
 ALT="$ \alpha = .05$">.  An
appropriate test statistic for testing hypotheses concenring means (see section 6.5) is 
<!-- MATH
 \begin{displaymath}
z = \frac{\X - \mu}{\frac{s}{\sqrt{n}}}.
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="64" HEIGHT="47" ALIGN="MIDDLE" BORDER="0"
 SRC="img109.gif"
 ALT="$\displaystyle z = \frac{\X - \mu}{\frac{s}{\sqrt{n}}}.$">
</DIV><P></P>
Recall from the last chapter that for large sample sizes the above statistic has an approximate normal
distribution.  This means that in step four we will use the normal distribution to determine the
rejection region.  

<P>
In figure 3 we see a normal distribution with a supposed mean of <IMG
 WIDTH="51" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img103.gif"
 ALT="$ \mu = 26$">.  This corresponds
to a z-value of <IMG
 WIDTH="41" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img110.gif"
 ALT="$ z = 0$">.  Given the alternative <IMG
 WIDTH="51" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img104.gif"
 ALT="$ \mu &gt; 26$"> it is clear that high values of the mean
will lead to rejection.  The 5% level tells us how high - only the highest 5% will lead to
rejection.  From the standard normal table we find (as in chapter four) that a z-value of <IMG
 WIDTH="62" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img111.gif"
 ALT="$ z = 1.65$">
cuts off the highest 5%.  This is called the <B>critical z-value</B>, which we denote by <IMG
 WIDTH="18" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img112.gif"
 ALT="$ z_c$">. Here
then i <!-- MATH
 $z_c = 1.65$
 -->
<IMG
 WIDTH="67" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img113.gif"
 ALT="$ z_c = 1.65$">.  This is the cutoff above which there will be rejection.  Notice that since the
alternative is one-sided only one tail of the normal curve leads to rejection.  Tests like this are
then called <B>one-tailed tests</B>.  If both tails led to rejection it would be called a <B>two-tailed test</B>.

<P>

<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="336" HEIGHT="195" ALIGN="MIDDLE" BORDER="0"
 SRC="Anal_Var_3.gif"
>
</DIV><P></P>

<DIV ALIGN="CENTER">
figure 3  Rejection Region</DIV>

<P>
<P></P>

<P>
The sample results are:
<!-- MATH
 \begin{displaymath}
\X = 27.5, s = 4.5 \text{ and } n = 64
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="105" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img114.gif"
 ALT="$\displaystyle \X = 27.5, s = 4.5$">&nbsp; &nbsp; and <IMG
 WIDTH="51" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img115.gif"
 ALT="$\displaystyle n = 64$">
</DIV><P></P>
therefore the value of the test statistic is
<!-- MATH
 \begin{displaymath}
z = \frac{27.5 - 26}{\frac{4.5}{8}} = 2.67.
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="155" HEIGHT="49" ALIGN="MIDDLE" BORDER="0"
 SRC="img116.gif"
 ALT="$\displaystyle z = \frac{27.5 - 26}{\frac{4.5}{8}} = 2.67.$">
</DIV><P></P>
This value falls in the rejection region and therefore the results are significant.  It follows
that the null hypothesis of <IMG
 WIDTH="51" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img103.gif"
 ALT="$ \mu = 26$"> is rejected in favor of the alternative <IMG
 WIDTH="51" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img104.gif"
 ALT="$ \mu &gt; 26$">.

<P>
The results would be reported in the following manner.

<P><P>
<BR>
At a 5% level the result were significant.  Therefore the null hypothesis that the mean was 26 is
rejected in favor of the alternative that the mean is greater than 26.

<P><P>
<BR>

<P>
From A normal table we see that there is a probability of only .0037 of obtaining a z-value of
over 2.67.  Hence the P-value of the above test results is .0037.  This is below <!-- MATH
 $\alpha = .05$
 -->
<IMG
 WIDTH="56" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img108.gif"
 ALT="$ \alpha = .05$">. 
Again using the P-value criterion the null hypothesis would be rejected since the P-value is lower
than the chosen level.

<P><P>
<BR>

<P>
It should be clear from this example that the testing procedure is rather straightforward once an
appropriate test statistic and its sampling distribution is known.  Therefore what must be done
now is to describe the important testing situations  together with the
appropriate corresponding test statistics. 

<P><P>
<BR>

<P>
<DIV ALIGN="CENTER">
<B>(3) OVERVIEW OF PARAMETRIC TESTING</B></DIV>

<P><P>
<BR>

<P>
In most practical testing situations there are three population parameters that may be of interest:
<B>means</B>, <B>standard deviations</B> and <B>proportions</B>.  Hypotheses on these parameters can be
tested in several different ways.

<P>
In a <B>one-sample test</B>, the value of the parameter is tested against some predetermined standard
or target value.  The sample results in a single sample are used to either accept of reject that
standard.  Both examples in the previous section were one sample tests.

<P>
In a <B>two-sample test</B>, independent samples from two different populations are used to determine
comparisons between the parameters of the two populations.  For example in comparing whether the
completion time of two surgical procedures differs between hospital A and hospital B independent
samples would be drawn from each and then compared.  

<P>
In <B>multiple sample tests</B> parameters from many different populations are tested in one test.  

<P>
Therefore there are nine basic situations which the statistical analyst must be acquainted with:
one sample, two sample and multiple sample for means; 
one sample, two sample and multiple sample for standard deviations; and 
one sample, two sample and multiple sample for proportions.  Within each of these nine basic
situations testing may differ depending on whether large or small samples are drawn.  The analyst
must be acquainted with this also.  The chart in figure 4  gives an overview picture of this
parametric testing. 

<P>

<P></P>

<DIV ALIGN="CENTER">
<IMG
 WIDTH="336" HEIGHT="195" ALIGN="MIDDLE" BORDER="0"
 SRC="Anal_Var_4.gif"
>
</DIV><P></P>

<DIV ALIGN="CENTER">
figure 4  Parametric Testing Overview</DIV>

<P></P>

<P><P>
<BR>

<P>
Tests of means are generally called <B>t-tests</B> because they use the t-distribution  Multiple
sample tests of means fall into what are called <B>analysis of variance</B> or <B>ANOVA</B>
procedures.   One sample tests of standard deviations use the
chi-square distribution while two sample and multiple sample tests for standard deviations use the
F-distribution and are called <B>F-tests</B>.    One and two sample tests of proportions are called
<B>p-tests </B> and are usually based on the normal distribution.  Multiple sample tests use the
chi-square distribution and will be discussed in the next chapter.  Multiple sample procedures can
also be used for two sample testing.    

<P>

<P><P>
<BR>

<P>
<DIV ALIGN="CENTER">
<B>(3) HYPTHESIS TESTS FOR A SINGLE VARIANCE </B></DIV>
 <BR>
<DIV ALIGN="CENTER">
<B>OR STANDARD
DEVIATION</B></DIV>
 
<P><P>
<BR>

<P>
The variation of a population or a data set is crucial to understanding research results.  Therefore
it is often quite important to test questions about variances and standard deviations.  In doing
such tests we generally assume that the parent population is normal.  Test results concerning
variances are equivalent to tests concerning standard deviations.

<P>
For a one variable data set, representing a single population, null hypotheses are of the form
<!-- MATH
 \begin{displaymath}
H_0: \sigma^2 = \sigma_0^2 \tag 1
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="100" HEIGHT="35" ALIGN="MIDDLE" BORDER="0"
 SRC="img117.gif"
 ALT="$\displaystyle H_0: \sigma^2 = \sigma_0^2 \tag 1$">
</DIV><P></P>
or
<!-- MATH
 \begin{displaymath}
H_0: \sigma = \sigma_0.
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="89" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img118.gif"
 ALT="$\displaystyle H_0: \sigma = \sigma_0.$">
</DIV><P></P>
In these, <IMG
 WIDTH="14" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img3.gif"
 ALT="$ \sigma$"> is the population standard deviation and <IMG
 WIDTH="20" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img119.gif"
 ALT="$ \sigma_0$"> is a particular value.

<P>
An appropriate test statistic for dealing with (1) is
<!-- MATH
 \begin{displaymath}
\chi^2 = \frac{(n-1)s^2}{\sigma_0^2} \tag 2
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="118" HEIGHT="55" ALIGN="MIDDLE" BORDER="0"
 SRC="img120.gif"
 ALT="$\displaystyle \chi^2 = \frac{(n-1)s^2}{\sigma_0^2} \tag 2$">
</DIV><P></P>
which has a chi-square distribution with <IMG
 WIDTH="41" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img46.gif"
 ALT="$ n-1$"> degrees of freedom.  Therefore the critical values
and rejection region will be found from the chi-square distribution.

<P>
EXAMPLE 

<P>
A filling machine is supposed to have a variance of .01 liters.  A random
sample of 16 fills showed a sample variance of .014 liters.  Is this significant at a 5% level that
the variance is too large.

<P>
The null and alternative hypotheses are
<!-- MATH
 \begin{displaymath}
H_0: \sigma^2 = .01
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="96" HEIGHT="35" ALIGN="MIDDLE" BORDER="0"
 SRC="img121.gif"
 ALT="$\displaystyle H_0: \sigma^2 = .01$">
</DIV><P></P>
<!-- MATH
 \begin{displaymath}
H_1: \sigma^2 > .01.
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="100" HEIGHT="35" ALIGN="MIDDLE" BORDER="0"
 SRC="img122.gif"
 ALT="$\displaystyle H_1: \sigma^2 &gt; .01.$">
</DIV><P></P>
The test statistic is given by 6.7.2 which follows a chi-square distribution with 15 degrees of
freedom.  The critical chi-square value would be found from the chi-square table
<!-- MATH
 \begin{displaymath}
\chi^2_c = \chi^2_{.05,15} = 24.996.
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="156" HEIGHT="35" ALIGN="MIDDLE" BORDER="0"
 SRC="img123.gif"
 ALT="$\displaystyle \chi^2_c = \chi^2_{.05,15} = 24.996.$">
</DIV><P></P>
The sample results were that <IMG
 WIDTH="51" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img59.gif"
 ALT="$ n = 16$"> and <!-- MATH
 $s^2 = .014$
 -->
<IMG
 WIDTH="68" HEIGHT="17" ALIGN="BOTTOM" BORDER="0"
 SRC="img124.gif"
 ALT="$ s^2 = .014$"> hence the test statistic value is
<!-- MATH
 \begin{displaymath}
\chi^2 = \frac{(15)(.014)}{.01} = 21.
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="157" HEIGHT="53" ALIGN="MIDDLE" BORDER="0"
 SRC="img125.gif"
 ALT="$\displaystyle \chi^2 = \frac{(15)(.014)}{.01} = 21.$">
</DIV><P></P>
This is not significant so therefore at a 5% level there is no evidence that the variance is too
high.  

<P><P>
<BR>

<P>
There is a large sample technique that can be employed also with tests of variances for a one
variable data set.  If the sample size is large (<IMG
 WIDTH="51" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img126.gif"
 ALT="$ n &gt; 30 $">) then
<!-- MATH
 \begin{displaymath}
z = \frac{s-\sigma_0}{\frac{\sigma_0}{\sqrt{2n}}} \3
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="80" HEIGHT="47" ALIGN="MIDDLE" BORDER="0"
 SRC="img127.gif"
 ALT="$\displaystyle z = \frac{s-\sigma_0}{\frac{\sigma_0}{\sqrt{2n}}} \3$">
</DIV><P></P>
has an approximate normal distribution.  Notice in this test statistic we use the standard deviation
rather than the variance.

<P><P>
<BR>

<P>
EXAMPLE

<P>
Suppose that in the filling machine of the first example, which is
supposed to have a variance of .01 liters, a random sample of 100 fills showed a sample variance of
.014 liters.  Is this significant at a 5% level that the variance is too large.

<P>
The null and alternative hypotheses are
<!-- MATH
 \begin{displaymath}
H_0: \sigma^2 = .01
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="96" HEIGHT="35" ALIGN="MIDDLE" BORDER="0"
 SRC="img121.gif"
 ALT="$\displaystyle H_0: \sigma^2 = .01$">
</DIV><P></P>
<!-- MATH
 \begin{displaymath}
H_1: \sigma^2 > .01.
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="100" HEIGHT="35" ALIGN="MIDDLE" BORDER="0"
 SRC="img122.gif"
 ALT="$\displaystyle H_1: \sigma^2 &gt; .01.$">
</DIV><P></P>
Since now <IMG
 WIDTH="59" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img128.gif"
 ALT="$ n = 100$"> a large sample procedure can be used and the test statistic is given by 6.7.3
which follows a normal distribution.  The critical z-value
for 5% and a one-sided test is <!-- MATH
 $z_c = 1.65$
 -->
<IMG
 WIDTH="67" HEIGHT="28" ALIGN="MIDDLE" BORDER="0"
 SRC="img113.gif"
 ALT="$ z_c = 1.65$">.  Here <!-- MATH
 $\sigma_0^2 = .01$
 -->
<IMG
 WIDTH="62" HEIGHT="33" ALIGN="MIDDLE" BORDER="0"
 SRC="img129.gif"
 ALT="$ \sigma_0^2 = .01$"> so <!-- MATH
 $\sigma_0 = \sqrt{.01} =
.1$
 -->
<IMG
 WIDTH="109" HEIGHT="36" ALIGN="MIDDLE" BORDER="0"
 SRC="img130.gif"
 ALT="$ \sigma_0 = \sqrt{.01} =
.1$">. The sample results were 
 <!-- MATH
 \begin{displaymath}
n = 100, s^2 = .014 \implies s = \sqrt{.014} = .118.
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="254" HEIGHT="38" ALIGN="MIDDLE" BORDER="0"
 SRC="img131.gif"
 ALT="$\displaystyle n = 100, s^2 = .014 \implies s = \sqrt{.014} = .118.$">
</DIV><P></P>
The test statistic value is
<!-- MATH
 \begin{displaymath}
z = \frac{.118-.1}{\frac{.118}{\sqrt{200}}} = 2.16.
\end{displaymath}
 -->
<P></P>
<DIV ALIGN="CENTER">
<IMG
 WIDTH="151" HEIGHT="49" ALIGN="MIDDLE" BORDER="0"
 SRC="img132.gif"
 ALT="$\displaystyle z = \frac{.118-.1}{\frac{.118}{\sqrt{200}}} = 2.16.$">
</DIV><P></P>
This is  significant so therefore at a 5% level there is evidence that the variance is too
high.  

<P><P>
<BR>

<P>
The significance in this second case points out that tests are more powerful for larger sample
sizes.

<P>
Note that in conducting these tests using MAGNUSSTAT the P-values will be computed automatically
and the appropriate decision ( accept or reject) based on the user defined level of significance
will be presented in the output box. 

<P>;''
<BR><HR>

</BODY>
</HTML>
